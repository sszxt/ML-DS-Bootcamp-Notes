{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0248ea3a",
      "metadata": {},
      "source": [
        "# Real-World Use Case: Multiprocessing for Data Processing\n",
        "\n",
        "Multiprocessing shines when you have CPU-intensive tasks that can be parallelized. This notebook demonstrates practical examples like data transformation, image processing simulation, and batch computations.\n",
        "\n",
        "## What We'll Learn\n",
        "\n",
        "1. Data Transformation with Multiprocessing\n",
        "2. Batch Processing Large Datasets\n",
        "3. Parallel Calculations\n",
        "4. Performance Comparison\n",
        "5. Best Practices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ea9085",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Data Transformation with ProcessPoolExecutor\n",
        "\n",
        "Processing large lists of data in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64586f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import time\n",
        "\n",
        "def process_data_chunk(chunk):\n",
        "    \"\"\"Simulate CPU-intensive data processing\"\"\"\n",
        "    # Example: Complex mathematical transformations\n",
        "    result = []\n",
        "    for num in chunk:\n",
        "        # Simulate CPU-intensive work\n",
        "        value = sum([num ** 2 + i for i in range(1000)])\n",
        "        result.append(value)\n",
        "    return result\n",
        "\n",
        "# Generate large dataset\n",
        "data = list(range(10000))\n",
        "\n",
        "# Split data into chunks\n",
        "def chunk_list(lst, chunk_size):\n",
        "    for i in range(0, len(lst), chunk_size):\n",
        "        yield lst[i:i + chunk_size]\n",
        "\n",
        "chunks = list(chunk_list(data, 1000))  # 10 chunks of 1000 items\n",
        "\n",
        "# Sequential processing\n",
        "print(\"=== Sequential Processing ===\")\n",
        "start = time.time()\n",
        "sequential_results = []\n",
        "for chunk in chunks:\n",
        "    sequential_results.extend(process_data_chunk(chunk))\n",
        "sequential_time = time.time() - start\n",
        "print(f\"Time: {sequential_time:.2f} seconds\")\n",
        "\n",
        "# Parallel processing with multiprocessing\n",
        "print(\"\\n=== Parallel Processing (Multiprocessing) ===\")\n",
        "start = time.time()\n",
        "with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "    parallel_results = []\n",
        "    for result in executor.map(process_data_chunk, chunks):\n",
        "        parallel_results.extend(result)\n",
        "parallel_time = time.time() - start\n",
        "print(f\"Time: {parallel_time:.2f} seconds\")\n",
        "\n",
        "print(f\"\\nSpeedup: {sequential_time/parallel_time:.2f}x faster!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3505dfc",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Image Processing Simulation\n",
        "\n",
        "Simulating parallel image processing (resize, filter, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae760744",
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import time\n",
        "\n",
        "def process_image(image_path):\n",
        "    \"\"\"Simulate image processing (resize, filter, compress, etc.)\"\"\"\n",
        "    # Simulate CPU-intensive operations\n",
        "    time.sleep(0.1)  # I/O: reading image\n",
        "    \n",
        "    # Simulate heavy processing (filters, transformations)\n",
        "    result = 0\n",
        "    for i in range(1000000):\n",
        "        result += i ** 2\n",
        "    \n",
        "    return f\"Processed: {image_path}\"\n",
        "\n",
        "# Simulate batch of images\n",
        "image_files = [f\"image_{i}.jpg\" for i in range(20)]\n",
        "\n",
        "print(\"Processing 20 images...\")\n",
        "start = time.time()\n",
        "\n",
        "# Parallel image processing\n",
        "with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "    results = list(executor.map(process_image, image_files))\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(f\"\\nAll images processed in {elapsed:.2f} seconds\")\n",
        "print(f\"Average time per image: {elapsed/len(image_files):.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d0801e",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "1. **Best For CPU-Bound Tasks**:\n",
        "   - Data transformations\n",
        "   - Mathematical computations\n",
        "   - Image/video processing\n",
        "   - Scientific calculations\n",
        "   - Machine learning training\n",
        "\n",
        "2. **Performance Gains**:\n",
        "   - Near-linear speedup with number of cores\n",
        "   - 2-4x faster on typical quad-core machines\n",
        "   - Bypasses Python's GIL completely\n",
        "\n",
        "3. **Best Practices**:\n",
        "   - Chunk large datasets for efficient distribution\n",
        "   - Use `ProcessPoolExecutor` for simplicity\n",
        "   - Balance chunk size vs overhead\n",
        "   - Consider pickle overhead for large objects\n",
        "   - Don't create more processes than CPU cores\n",
        "\n",
        "4. **When NOT to Use**:\n",
        "   - I/O-bound tasks (use threading)\n",
        "   - Small, quick tasks (overhead > benefit)\n",
        "   - Tasks with large data transfer between processes\n",
        "\n",
        "**Real-World Applications:**\n",
        "- Video encoding/transcoding\n",
        "- Data science preprocessing\n",
        "- Batch file processing\n",
        "- Scientific simulations\n",
        "- Cryptocurrency mining\n",
        "- Machine learning model training\n",
        "\n",
        "Multiprocessing unlocks the full power of modern multi-core CPUs!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
