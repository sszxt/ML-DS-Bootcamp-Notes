{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Central Tendency\n",
    "\n",
    "Measures of central tendency are statistical metrics that identify a single value as representative of an entire dataset. They provide a summary of where the \"center\" or \"typical\" value of the data lies. Understanding these measures is fundamental for data analysis, machine learning feature engineering, and making data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Central Tendency](#introduction)\n",
    "2. [The Three Main Measures](#three-measures)\n",
    "3. [Mean (Average)](#mean)\n",
    "   - Arithmetic Mean\n",
    "   - Geometric Mean\n",
    "   - Harmonic Mean\n",
    "4. [Median](#median)\n",
    "5. [Mode](#mode)\n",
    "6. [Comparison and When to Use Each](#comparison)\n",
    "7. [Effect of Outliers](#outliers)\n",
    "8. [Skewness and Central Tendency](#skewness)\n",
    "9. [Real-World Applications](#applications)\n",
    "10. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to Central Tendency <a id=\"introduction\"></a>\n",
    "\n",
    "**What is Central Tendency?**\n",
    "\n",
    "Central tendency refers to the measure that represents the center or middle of a data distribution. It answers the question: \"What is a typical value in this dataset?\"\n",
    "\n",
    "**Why Does it Matter in Data Science and ML?**\n",
    "\n",
    "- **Data Summarization**: Condense large datasets into single representative values\n",
    "- **Feature Engineering**: Create new features based on central values\n",
    "- **Anomaly Detection**: Identify outliers by comparing values to central measures\n",
    "- **Model Evaluation**: Understand baseline performance metrics\n",
    "- **Data Imputation**: Fill missing values with central tendency measures\n",
    "- **Business Insights**: Make informed decisions based on typical values (average sales, median income, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import gmean, hmean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The Three Main Measures <a id=\"three-measures\"></a>\n",
    "\n",
    "The three primary measures of central tendency are:\n",
    "\n",
    "| Measure | Definition | Best Used For |\n",
    "|---------|------------|---------------|\n",
    "| **Mean** | Average of all values | Symmetric distributions without outliers |\n",
    "| **Median** | Middle value when data is ordered | Skewed distributions or data with outliers |\n",
    "| **Mode** | Most frequently occurring value | Categorical data or finding the most common value |\n",
    "\n",
    "Each measure has its strengths and weaknesses, and choosing the right one depends on your data characteristics and analysis goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset for demonstration\n",
    "data = np.array([23, 25, 27, 28, 30, 32, 35, 38, 40, 42])\n",
    "\n",
    "# Calculate all three measures\n",
    "mean_value = np.mean(data)\n",
    "median_value = np.median(data)\n",
    "mode_result = stats.mode(data, keepdims=True)\n",
    "mode_value = mode_result.mode[0]\n",
    "\n",
    "print(\"Sample Data:\", data)\n",
    "print(f\"\\nMean: {mean_value}\")\n",
    "print(f\"Median: {median_value}\")\n",
    "print(f\"Mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Mean (Average) <a id=\"mean\"></a>\n",
    "\n",
    "The **mean** is the sum of all values divided by the number of values. It's the most commonly used measure of central tendency.\n",
    "\n",
    "### 3.1 Arithmetic Mean\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n} = \\frac{x_1 + x_2 + ... + x_n}{n}$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{x}$ = mean\n",
    "- $x_i$ = individual values\n",
    "- $n$ = number of values\n",
    "\n",
    "**Characteristics:**\n",
    "- Takes all values into account\n",
    "- Can be affected by extreme values (outliers)\n",
    "- Only applicable to numerical data\n",
    "- Suitable for interval and ratio scales\n",
    "\n",
    "**When to Use:**\n",
    "- Data is symmetrically distributed\n",
    "- No significant outliers\n",
    "- Need to use all data points in calculation\n",
    "- Performing further statistical calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Arithmetic Mean - Multiple Methods\n",
    "\n",
    "# Sample data: Test scores\n",
    "test_scores = [78, 85, 92, 88, 76, 90, 85, 88, 92, 80]\n",
    "\n",
    "# Method 1: Using pure Python\n",
    "mean_python = sum(test_scores) / len(test_scores)\n",
    "\n",
    "# Method 2: Using NumPy\n",
    "mean_numpy = np.mean(test_scores)\n",
    "\n",
    "# Method 3: Using Pandas\n",
    "df = pd.DataFrame({'scores': test_scores})\n",
    "mean_pandas = df['scores'].mean()\n",
    "\n",
    "# Method 4: Using statistics module\n",
    "import statistics\n",
    "mean_stats = statistics.mean(test_scores)\n",
    "\n",
    "print(\"Test Scores:\", test_scores)\n",
    "print(f\"\\nMean (Python): {mean_python:.2f}\")\n",
    "print(f\"Mean (NumPy): {mean_numpy:.2f}\")\n",
    "print(f\"Mean (Pandas): {mean_pandas:.2f}\")\n",
    "print(f\"Mean (Statistics): {mean_stats:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Geometric Mean\n",
    "\n",
    "The **geometric mean** is the nth root of the product of n values. It's particularly useful for data that represents rates of change or ratios.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$GM = \\sqrt[n]{x_1 \\times x_2 \\times ... \\times x_n} = \\left(\\prod_{i=1}^{n} x_i\\right)^{1/n}$$\n",
    "\n",
    "**When to Use:**\n",
    "- Calculating average growth rates\n",
    "- Analyzing percentage changes\n",
    "- Comparing different items with different properties\n",
    "- Data spans several orders of magnitude\n",
    "- Investment returns over time\n",
    "\n",
    "**Important Note:** All values must be positive for geometric mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Mean Example: Investment Returns\n",
    "\n",
    "# Annual growth rates (as multipliers, not percentages)\n",
    "# Year 1: +10% growth = 1.10\n",
    "# Year 2: -5% loss = 0.95\n",
    "# Year 3: +15% growth = 1.15\n",
    "# Year 4: +8% growth = 1.08\n",
    "\n",
    "growth_rates = [1.10, 0.95, 1.15, 1.08]\n",
    "\n",
    "# Calculate geometric mean\n",
    "from scipy.stats import gmean\n",
    "geometric_mean = gmean(growth_rates)\n",
    "\n",
    "# Convert back to percentage\n",
    "avg_growth_rate = (geometric_mean - 1) * 100\n",
    "\n",
    "# Compare with arithmetic mean (which would be incorrect here)\n",
    "arithmetic_mean = np.mean(growth_rates)\n",
    "arithmetic_growth_rate = (arithmetic_mean - 1) * 100\n",
    "\n",
    "print(\"Investment Growth Rates (as multipliers):\", growth_rates)\n",
    "print(f\"\\nGeometric Mean: {geometric_mean:.4f}\")\n",
    "print(f\"Average Annual Growth Rate (Correct): {avg_growth_rate:.2f}%\")\n",
    "print(f\"\\nArithmetic Mean: {arithmetic_mean:.4f}\")\n",
    "print(f\"Arithmetic Growth Rate (Incorrect): {arithmetic_growth_rate:.2f}%\")\n",
    "print(\"\\n** Geometric mean is the correct measure for compound growth! **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Geometric Mean Example: Image Aspect Ratios\n",
    "\n",
    "# Different aspect ratios\n",
    "aspect_ratios = [16/9, 4/3, 21/9, 1/1]  # Wide, standard, ultrawide, square\n",
    "\n",
    "# Geometric mean gives a balanced \"typical\" aspect ratio\n",
    "typical_ratio = gmean(aspect_ratios)\n",
    "\n",
    "print(\"Aspect Ratios:\", [f\"{ratio:.3f}\" for ratio in aspect_ratios])\n",
    "print(f\"Geometric Mean (Typical Ratio): {typical_ratio:.3f}\")\n",
    "print(f\"Arithmetic Mean (Not meaningful here): {np.mean(aspect_ratios):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Harmonic Mean\n",
    "\n",
    "The **harmonic mean** is the reciprocal of the arithmetic mean of reciprocals. It's useful for rates and ratios.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$HM = \\frac{n}{\\sum_{i=1}^{n} \\frac{1}{x_i}} = \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + ... + \\frac{1}{x_n}}$$\n",
    "\n",
    "**When to Use:**\n",
    "- Calculating average speeds or rates\n",
    "- Working with ratios or reciprocal relationships\n",
    "- F1 score in machine learning (harmonic mean of precision and recall)\n",
    "- Averaging rates (like km/hour or items/second)\n",
    "\n",
    "**Property:** Harmonic Mean ≤ Geometric Mean ≤ Arithmetic Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonic Mean Example: Average Speed\n",
    "\n",
    "# A car travels 100 km at 60 km/h, then returns 100 km at 40 km/h\n",
    "# What's the average speed for the entire trip?\n",
    "\n",
    "speeds = [60, 40]  # km/h\n",
    "\n",
    "# Calculate harmonic mean (correct for average speed)\n",
    "from scipy.stats import hmean\n",
    "avg_speed_harmonic = hmean(speeds)\n",
    "\n",
    "# Calculate arithmetic mean (incorrect for this scenario)\n",
    "avg_speed_arithmetic = np.mean(speeds)\n",
    "\n",
    "# Verify with actual calculation\n",
    "total_distance = 100 + 100  # km\n",
    "time1 = 100 / 60  # hours\n",
    "time2 = 100 / 40  # hours\n",
    "total_time = time1 + time2\n",
    "actual_avg_speed = total_distance / total_time\n",
    "\n",
    "print(\"Speeds:\", speeds, \"km/h\")\n",
    "print(f\"\\nHarmonic Mean (Correct): {avg_speed_harmonic:.2f} km/h\")\n",
    "print(f\"Actual Average Speed: {actual_avg_speed:.2f} km/h\")\n",
    "print(f\"\\nArithmetic Mean (Incorrect): {avg_speed_arithmetic:.2f} km/h\")\n",
    "print(\"\\n** Harmonic mean correctly calculates average speed! **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonic Mean in Machine Learning: F1 Score\n",
    "\n",
    "# Precision and Recall values\n",
    "precision = 0.85\n",
    "recall = 0.75\n",
    "\n",
    "# F1 Score is the harmonic mean of precision and recall\n",
    "f1_score = hmean([precision, recall])\n",
    "\n",
    "# Compare with arithmetic mean\n",
    "arithmetic_avg = (precision + recall) / 2\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"\\nF1 Score (Harmonic Mean): {f1_score:.4f}\")\n",
    "print(f\"Arithmetic Mean: {arithmetic_avg:.4f}\")\n",
    "print(\"\\n** F1 Score penalizes extreme differences between precision and recall **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of All Three Means\n",
    "\n",
    "data = [2, 4, 8, 16, 32]\n",
    "\n",
    "arithmetic = np.mean(data)\n",
    "geometric = gmean(data)\n",
    "harmonic = hmean(data)\n",
    "\n",
    "print(\"Data:\", data)\n",
    "print(f\"\\nArithmetic Mean: {arithmetic:.2f}\")\n",
    "print(f\"Geometric Mean: {geometric:.2f}\")\n",
    "print(f\"Harmonic Mean: {harmonic:.2f}\")\n",
    "print(f\"\\nRelationship: HM ({harmonic:.2f}) ≤ GM ({geometric:.2f}) ≤ AM ({arithmetic:.2f})\")\n",
    "\n",
    "# Visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "means = [harmonic, geometric, arithmetic]\n",
    "labels = ['Harmonic Mean', 'Geometric Mean', 'Arithmetic Mean']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = plt.bar(labels, means, color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.title('Comparison of Different Types of Means', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, max(means) * 1.2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean in zip(bars, means):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{mean:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Median <a id=\"median\"></a>\n",
    "\n",
    "The **median** is the middle value when data is arranged in ascending or descending order. It divides the dataset into two equal halves.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "For **odd** number of values:\n",
    "$$Median = x_{\\frac{n+1}{2}}$$\n",
    "\n",
    "For **even** number of values:\n",
    "$$Median = \\frac{x_{\\frac{n}{2}} + x_{\\frac{n}{2}+1}}{2}$$\n",
    "\n",
    "**Characteristics:**\n",
    "- Not affected by extreme values (robust to outliers)\n",
    "- Represents the 50th percentile\n",
    "- Only requires ordinal data (can be ranked)\n",
    "- Better for skewed distributions\n",
    "\n",
    "**When to Use:**\n",
    "- Data has outliers or is skewed\n",
    "- Reporting income, house prices, or other financial data\n",
    "- Need a robust measure unaffected by extremes\n",
    "- Ordinal data (rankings, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Median - Multiple Scenarios\n",
    "\n",
    "# Scenario 1: Odd number of values\n",
    "odd_data = [12, 15, 18, 20, 22, 25, 30]\n",
    "median_odd = np.median(odd_data)\n",
    "\n",
    "print(\"Odd number of values:\", odd_data)\n",
    "print(f\"Median: {median_odd} (the middle value)\\n\")\n",
    "\n",
    "# Scenario 2: Even number of values\n",
    "even_data = [12, 15, 18, 20, 22, 25, 30, 35]\n",
    "median_even = np.median(even_data)\n",
    "\n",
    "print(\"Even number of values:\", even_data)\n",
    "print(f\"Median: {median_even} (average of two middle values: 20 and 22)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median vs Mean: Impact of Outliers\n",
    "\n",
    "# Salaries in a small company (in thousands)\n",
    "salaries_normal = [45, 48, 50, 52, 55, 58, 60, 62, 65]\n",
    "# CEO's salary is added\n",
    "salaries_with_ceo = [45, 48, 50, 52, 55, 58, 60, 62, 65, 500]\n",
    "\n",
    "# Calculate mean and median for both\n",
    "mean_normal = np.mean(salaries_normal)\n",
    "median_normal = np.median(salaries_normal)\n",
    "\n",
    "mean_with_ceo = np.mean(salaries_with_ceo)\n",
    "median_with_ceo = np.median(salaries_with_ceo)\n",
    "\n",
    "print(\"Salaries without CEO:\", salaries_normal)\n",
    "print(f\"Mean: ${mean_normal:.2f}k, Median: ${median_normal:.2f}k\\n\")\n",
    "\n",
    "print(\"Salaries with CEO:\", salaries_with_ceo)\n",
    "print(f\"Mean: ${mean_with_ceo:.2f}k, Median: ${median_with_ceo:.2f}k\\n\")\n",
    "\n",
    "print(\"Impact of outlier:\")\n",
    "print(f\"Mean increased by: ${mean_with_ceo - mean_normal:.2f}k ({((mean_with_ceo/mean_normal - 1)*100):.1f}%)\")\n",
    "print(f\"Median increased by: ${median_with_ceo - median_normal:.2f}k ({((median_with_ceo/median_normal - 1)*100):.1f}%)\")\n",
    "print(\"\\n** Median is more robust to outliers! **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Median vs Mean with Outliers\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Without outlier\n",
    "axes[0].hist(salaries_normal, bins=15, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(mean_normal, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_normal:.1f}k')\n",
    "axes[0].axvline(median_normal, color='green', linestyle='--', linewidth=2, label=f'Median: ${median_normal:.1f}k')\n",
    "axes[0].set_xlabel('Salary (in thousands)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Salaries Without CEO (No Outlier)', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: With outlier\n",
    "axes[1].hist(salaries_with_ceo, bins=15, color='salmon', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(mean_with_ceo, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_with_ceo:.1f}k')\n",
    "axes[1].axvline(median_with_ceo, color='green', linestyle='--', linewidth=2, label=f'Median: ${median_with_ceo:.1f}k')\n",
    "axes[1].set_xlabel('Salary (in thousands)', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Salaries With CEO (Outlier Present)', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the mean shifts significantly toward the outlier,\")\n",
    "print(\"while the median remains stable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Mode <a id=\"mode\"></a>\n",
    "\n",
    "The **mode** is the value that appears most frequently in a dataset. A dataset can have:\n",
    "- **No mode**: All values occur with equal frequency\n",
    "- **Unimodal**: One value occurs most frequently\n",
    "- **Bimodal**: Two values occur with equal highest frequency\n",
    "- **Multimodal**: More than two values occur with equal highest frequency\n",
    "\n",
    "**Characteristics:**\n",
    "- Can be used with categorical, ordinal, and numerical data\n",
    "- Not affected by extreme values\n",
    "- May not be unique\n",
    "- May not exist\n",
    "- Most useful for categorical data\n",
    "\n",
    "**When to Use:**\n",
    "- Categorical data (colors, brands, categories)\n",
    "- Finding the most common value\n",
    "- Discrete data with repeated values\n",
    "- Fashion, marketing, or consumer preference analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Mode - Different Scenarios\n",
    "\n",
    "# Scenario 1: Unimodal data\n",
    "unimodal_data = [1, 2, 2, 3, 3, 3, 4, 4, 5]\n",
    "mode_uni = stats.mode(unimodal_data, keepdims=True)\n",
    "\n",
    "print(\"Unimodal Data:\", unimodal_data)\n",
    "print(f\"Mode: {mode_uni.mode[0]} (appears {mode_uni.count[0]} times)\\n\")\n",
    "\n",
    "# Scenario 2: Bimodal data\n",
    "bimodal_data = [1, 2, 2, 2, 3, 4, 5, 5, 5]\n",
    "# scipy.stats.mode returns only one mode, so we'll find all modes manually\n",
    "from collections import Counter\n",
    "counter = Counter(bimodal_data)\n",
    "max_count = max(counter.values())\n",
    "modes = [k for k, v in counter.items() if v == max_count]\n",
    "\n",
    "print(\"Bimodal Data:\", bimodal_data)\n",
    "print(f\"Modes: {modes} (each appears {max_count} times)\\n\")\n",
    "\n",
    "# Scenario 3: No mode\n",
    "no_mode_data = [1, 2, 3, 4, 5]\n",
    "counter_no_mode = Counter(no_mode_data)\n",
    "\n",
    "print(\"Data with No Mode:\", no_mode_data)\n",
    "print(\"All values appear equally, so there's no mode\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode with Categorical Data - Real-World Example\n",
    "\n",
    "# Customer survey: Favorite product color\n",
    "colors = ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Blue', 'Yellow', \n",
    "          'Blue', 'Green', 'Blue', 'Red', 'Blue', 'Blue']\n",
    "\n",
    "# Find mode using pandas\n",
    "df_colors = pd.DataFrame({'Color': colors})\n",
    "mode_color = df_colors['Color'].mode()[0]\n",
    "mode_count = df_colors['Color'].value_counts()[mode_color]\n",
    "\n",
    "print(\"Customer Color Preferences:\", colors)\n",
    "print(f\"\\nMost Popular Color: {mode_color}\")\n",
    "print(f\"Number of votes: {mode_count}\\n\")\n",
    "\n",
    "# Show frequency distribution\n",
    "print(\"Frequency Distribution:\")\n",
    "print(df_colors['Color'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Mode\n",
    "\n",
    "# Create a dataset with clear mode\n",
    "shoe_sizes = [7, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12]\n",
    "\n",
    "# Calculate mode\n",
    "mode_size = stats.mode(shoe_sizes, keepdims=True).mode[0]\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique, counts = np.unique(shoe_sizes, return_counts=True)\n",
    "\n",
    "colors_bars = ['red' if size == mode_size else 'skyblue' for size in unique]\n",
    "bars = plt.bar(unique, counts, color=colors_bars, edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Shoe Size', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Shoe Sizes (Mode Highlighted in Red)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(unique)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mode (Most Common Shoe Size): {mode_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Comparison and When to Use Each Measure <a id=\"comparison\"></a>\n",
    "\n",
    "### Detailed Comparison Table\n",
    "\n",
    "| Aspect | Mean | Median | Mode |\n",
    "|--------|------|--------|------|\n",
    "| **Definition** | Average of all values | Middle value | Most frequent value |\n",
    "| **Calculation** | Sum / Count | Middle after sorting | Most common |\n",
    "| **Data Type** | Numerical only | Numerical/Ordinal | All types |\n",
    "| **Affected by outliers** | Yes (highly) | No (robust) | No |\n",
    "| **Uniqueness** | Always unique | Always unique | May not be unique |\n",
    "| **Existence** | Always exists | Always exists | May not exist |\n",
    "| **Use in further calculations** | Yes (variance, etc.) | Limited | No |\n",
    "| **Best for** | Symmetric data | Skewed data | Categorical data |\n",
    "\n",
    "### Decision Tree: Which Measure to Use?\n",
    "\n",
    "1. **Is your data categorical?**\n",
    "   - YES → Use **Mode**\n",
    "   - NO → Continue to step 2\n",
    "\n",
    "2. **Does your data have outliers or is it highly skewed?**\n",
    "   - YES → Use **Median**\n",
    "   - NO → Continue to step 3\n",
    "\n",
    "3. **Do you need to perform further statistical calculations?**\n",
    "   - YES → Use **Mean**\n",
    "   - NO → Use **Median** for robustness or **Mean** for completeness\n",
    "\n",
    "4. **Are you working with rates, ratios, or growth?**\n",
    "   - Growth rates → **Geometric Mean**\n",
    "   - Average speeds/rates → **Harmonic Mean**\n",
    "   - General average → **Arithmetic Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Comparison with Different Data Types\n",
    "\n",
    "# Create different types of distributions\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Normal distribution (Symmetric)\n",
    "normal_data = np.random.normal(100, 15, 1000)\n",
    "\n",
    "# 2. Right-skewed distribution\n",
    "skewed_data = np.random.exponential(30, 1000)\n",
    "\n",
    "# 3. Data with outliers\n",
    "with_outliers = np.concatenate([np.random.normal(50, 10, 950), \n",
    "                                 np.random.normal(200, 10, 50)])\n",
    "\n",
    "datasets = {\n",
    "    'Normal (Symmetric)': normal_data,\n",
    "    'Right-Skewed': skewed_data,\n",
    "    'With Outliers': with_outliers\n",
    "}\n",
    "\n",
    "# Calculate all measures for each dataset\n",
    "results = []\n",
    "for name, data in datasets.items():\n",
    "    results.append({\n",
    "        'Dataset': name,\n",
    "        'Mean': np.mean(data),\n",
    "        'Median': np.median(data),\n",
    "        'Mode': stats.mode(data.round(), keepdims=True).mode[0],\n",
    "        'Std Dev': np.std(data)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparison of Central Tendency Measures Across Different Distributions:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Normal distribution: Mean ≈ Median ≈ Mode\")\n",
    "print(\"- Skewed distribution: Mean > Median (pulled by tail)\")\n",
    "print(\"- With outliers: Mean is pulled away from median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    \n",
    "    axes[idx].hist(data, bins=50, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, \n",
    "                      label=f'Mean: {mean_val:.1f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, \n",
    "                      label=f'Median: {median_val:.1f}')\n",
    "    axes[idx].set_xlabel('Value', fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].set_title(name, fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Effect of Outliers <a id=\"outliers\"></a>\n",
    "\n",
    "**Outliers** are extreme values that differ significantly from other observations. They can heavily influence certain measures of central tendency.\n",
    "\n",
    "### Impact on Each Measure:\n",
    "\n",
    "1. **Mean**: \n",
    "   - HIGHLY affected by outliers\n",
    "   - Pulled in the direction of extreme values\n",
    "   - Can be misleading in presence of outliers\n",
    "\n",
    "2. **Median**: \n",
    "   - NOT affected by outliers (robust)\n",
    "   - Remains stable regardless of extreme values\n",
    "   - Best choice when outliers are present\n",
    "\n",
    "3. **Mode**: \n",
    "   - NOT affected by outliers\n",
    "   - Depends only on frequency, not magnitude\n",
    "   - May not change at all with outliers\n",
    "\n",
    "### Handling Outliers in Practice:\n",
    "\n",
    "- **Identify**: Use IQR method, Z-score, or visualization\n",
    "- **Investigate**: Determine if outliers are errors or genuine extreme values\n",
    "- **Decide**: Remove, transform, or use robust measures (median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating Impact of Outliers\n",
    "\n",
    "# Create a dataset and progressively add outliers\n",
    "base_data = np.random.normal(100, 10, 100)\n",
    "\n",
    "# Different scenarios\n",
    "scenarios = {\n",
    "    'No Outliers': base_data,\n",
    "    '1 Outlier': np.append(base_data, 300),\n",
    "    '5 Outliers': np.append(base_data, [300, 320, 310, 330, 315]),\n",
    "    '10 Outliers': np.append(base_data, np.random.uniform(300, 350, 10))\n",
    "}\n",
    "\n",
    "# Calculate impact\n",
    "impact_results = []\n",
    "for scenario_name, data in scenarios.items():\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    difference = abs(mean_val - median_val)\n",
    "    \n",
    "    impact_results.append({\n",
    "        'Scenario': scenario_name,\n",
    "        'Mean': f\"{mean_val:.2f}\",\n",
    "        'Median': f\"{median_val:.2f}\",\n",
    "        'Difference': f\"{difference:.2f}\",\n",
    "        'Sample Size': len(data)\n",
    "    })\n",
    "\n",
    "impact_df = pd.DataFrame(impact_results)\n",
    "print(\"\\nImpact of Outliers on Central Tendency:\")\n",
    "print(\"=\"*70)\n",
    "print(impact_df.to_string(index=False))\n",
    "print(\"\\nNotice how the mean increases dramatically while median stays stable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Outlier Impact\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (scenario_name, data) in enumerate(scenarios.items()):\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    \n",
    "    axes[idx].boxplot(data, vert=False, widths=0.5)\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, \n",
    "                      label=f'Mean: {mean_val:.1f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, \n",
    "                      label=f'Median: {median_val:.1f}')\n",
    "    axes[idx].set_xlabel('Value', fontsize=11)\n",
    "    axes[idx].set_title(scenario_name, fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Box plots clearly show outliers as individual points.\")\n",
    "print(\"Notice how mean (red) moves toward outliers while median (green) stays centered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outliers Using IQR Method\n",
    "\n",
    "def detect_outliers_iqr(data):\n",
    "    \"\"\"\n",
    "    Detect outliers using the Interquartile Range (IQR) method.\n",
    "    Values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR are considered outliers.\n",
    "    \"\"\"\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Example with real-world data\n",
    "house_prices = np.array([200, 220, 210, 230, 215, 225, 240, 235, 218, \n",
    "                         900, 205, 228, 232, 212, 1200])  # in thousands\n",
    "\n",
    "outliers, lower, upper = detect_outliers_iqr(house_prices)\n",
    "\n",
    "print(\"House Prices (in thousands):\", house_prices)\n",
    "print(f\"\\nOutlier Detection (IQR Method):\")\n",
    "print(f\"Lower Bound: ${lower:.2f}k\")\n",
    "print(f\"Upper Bound: ${upper:.2f}k\")\n",
    "print(f\"Outliers Detected: {outliers}\")\n",
    "print(f\"\\nMean (with outliers): ${np.mean(house_prices):.2f}k\")\n",
    "print(f\"Median (robust): ${np.median(house_prices):.2f}k\")\n",
    "print(f\"\\nMean (without outliers): ${np.mean(house_prices[~np.isin(house_prices, outliers)]):.2f}k\")\n",
    "print(\"\\n** Median is more representative of typical house price! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Skewness and Central Tendency <a id=\"skewness\"></a>\n",
    "\n",
    "**Skewness** measures the asymmetry of a probability distribution. It indicates whether data is concentrated on one side of the distribution.\n",
    "\n",
    "### Types of Skewness:\n",
    "\n",
    "1. **Symmetric (No Skew)**:\n",
    "   - Mean = Median = Mode\n",
    "   - Bell-shaped curve\n",
    "   - Skewness ≈ 0\n",
    "\n",
    "2. **Right-Skewed (Positive Skew)**:\n",
    "   - Mode < Median < Mean\n",
    "   - Long tail on the right\n",
    "   - Skewness > 0\n",
    "   - Examples: Income, house prices, age at death\n",
    "\n",
    "3. **Left-Skewed (Negative Skew)**:\n",
    "   - Mean < Median < Mode\n",
    "   - Long tail on the left\n",
    "   - Skewness < 0\n",
    "   - Examples: Test scores (if most students do well)\n",
    "\n",
    "### Skewness Formula:\n",
    "\n",
    "$$Skewness = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n} \\left(\\frac{x_i - \\bar{x}}{s}\\right)^3$$\n",
    "\n",
    "Where:\n",
    "- $n$ = sample size\n",
    "- $\\bar{x}$ = mean\n",
    "- $s$ = standard deviation\n",
    "\n",
    "### Empirical Relationship:\n",
    "\n",
    "For moderately skewed distributions:\n",
    "$$Mean - Mode \\approx 3(Mean - Median)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Different Skewed Distributions\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Symmetric (Normal) distribution\n",
    "symmetric = np.random.normal(50, 10, 1000)\n",
    "\n",
    "# 2. Right-skewed (Exponential) distribution\n",
    "right_skewed = np.random.exponential(20, 1000)\n",
    "\n",
    "# 3. Left-skewed (Negative of exponential, shifted)\n",
    "left_skewed = 100 - np.random.exponential(20, 1000)\n",
    "\n",
    "# Calculate statistics for each\n",
    "distributions = {\n",
    "    'Symmetric': symmetric,\n",
    "    'Right-Skewed': right_skewed,\n",
    "    'Left-Skewed': left_skewed\n",
    "}\n",
    "\n",
    "skew_results = []\n",
    "for name, data in distributions.items():\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    mode_val = stats.mode(data.round(), keepdims=True).mode[0]\n",
    "    skewness = stats.skew(data)\n",
    "    \n",
    "    skew_results.append({\n",
    "        'Distribution': name,\n",
    "        'Mean': f\"{mean_val:.2f}\",\n",
    "        'Median': f\"{median_val:.2f}\",\n",
    "        'Mode': f\"{mode_val:.2f}\",\n",
    "        'Skewness': f\"{skewness:.2f}\"\n",
    "    })\n",
    "\n",
    "skew_df = pd.DataFrame(skew_results)\n",
    "print(\"\\nSkewness and Central Tendency Relationships:\")\n",
    "print(\"=\"*70)\n",
    "print(skew_df.to_string(index=False))\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Symmetric: Mean ≈ Median, Skewness ≈ 0\")\n",
    "print(\"- Right-Skewed: Mean > Median, Skewness > 0\")\n",
    "print(\"- Left-Skewed: Mean < Median, Skewness < 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Skewness and Central Tendency\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "colors_dist = ['steelblue', 'coral', 'mediumseagreen']\n",
    "\n",
    "for idx, (name, data) in enumerate(distributions.items()):\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    skewness = stats.skew(data)\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[idx].hist(data, bins=50, color=colors_dist[idx], edgecolor='black', \n",
    "                   alpha=0.7, density=True)\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2.5, \n",
    "                      label=f'Mean: {mean_val:.1f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2.5, \n",
    "                      label=f'Median: {median_val:.1f}')\n",
    "    \n",
    "    # Add title with skewness\n",
    "    axes[idx].set_title(f'{name} Distribution (Skewness: {skewness:.2f})', \n",
    "                        fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value', fontsize=11)\n",
    "    axes[idx].set_ylabel('Density', fontsize=11)\n",
    "    axes[idx].legend(fontsize=10)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisual Guide:\")\n",
    "print(\"- Symmetric: Mean and median overlap\")\n",
    "print(\"- Right-Skewed: Mean is pulled to the right of median\")\n",
    "print(\"- Left-Skewed: Mean is pulled to the left of median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-World Example: Income Distribution (Right-Skewed)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate income distribution (typically right-skewed)\n",
    "# Most people earn moderate income, few earn very high income\n",
    "base_income = np.random.gamma(shape=2, scale=25000, size=950)\n",
    "high_earners = np.random.uniform(150000, 500000, 50)\n",
    "income_distribution = np.concatenate([base_income, high_earners])\n",
    "\n",
    "# Calculate statistics\n",
    "mean_income = np.mean(income_distribution)\n",
    "median_income = np.median(income_distribution)\n",
    "skewness_income = stats.skew(income_distribution)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(income_distribution, bins=50, color='gold', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(mean_income, color='red', linestyle='--', linewidth=2.5, \n",
    "            label=f'Mean: ${mean_income:,.0f}')\n",
    "plt.axvline(median_income, color='green', linestyle='--', linewidth=2.5, \n",
    "            label=f'Median: ${median_income:,.0f}')\n",
    "plt.xlabel('Annual Income ($)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f'Income Distribution (Right-Skewed, Skewness: {skewness_income:.2f})', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nIncome Analysis:\")\n",
    "print(f\"Mean Income: ${mean_income:,.2f}\")\n",
    "print(f\"Median Income: ${median_income:,.2f}\")\n",
    "print(f\"Difference: ${mean_income - median_income:,.2f}\")\n",
    "print(f\"\\nSkewness: {skewness_income:.2f} (Right-Skewed)\")\n",
    "print(\"\\n** Median is more representative of 'typical' income! **\")\n",
    "print(\"** Mean is inflated by high earners! **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Real-World Applications in Data Science and ML <a id=\"applications\"></a>\n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "1. **Data Imputation**:\n",
    "   - Fill missing values with mean (for symmetric data) or median (for skewed data)\n",
    "   - Use mode for categorical features\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Create aggregated features using central tendency\n",
    "   - Example: Average purchase amount per customer\n",
    "\n",
    "3. **Outlier Detection**:\n",
    "   - Compare values to mean ± 3*std or median ± IQR\n",
    "   - Identify anomalies in fraud detection\n",
    "\n",
    "4. **Data Normalization**:\n",
    "   - Mean-centering: Subtract mean from each value\n",
    "   - Median normalization: More robust to outliers\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "   - Baseline prediction using mean/median\n",
    "   - Compare model performance against simple central tendency\n",
    "\n",
    "6. **Business Analytics**:\n",
    "   - Average customer lifetime value\n",
    "   - Median transaction amount\n",
    "   - Most popular product (mode)\n",
    "\n",
    "7. **A/B Testing**:\n",
    "   - Compare means of two groups\n",
    "   - Use median for robust comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application 1: Data Imputation\n",
    "\n",
    "# Create a dataset with missing values\n",
    "np.random.seed(42)\n",
    "ages = np.random.normal(35, 10, 100)\n",
    "# Introduce some missing values (represented as NaN)\n",
    "missing_indices = np.random.choice(100, 15, replace=False)\n",
    "ages_with_missing = ages.copy()\n",
    "ages_with_missing[missing_indices] = np.nan\n",
    "\n",
    "# Create DataFrame\n",
    "df_impute = pd.DataFrame({'Age': ages_with_missing})\n",
    "\n",
    "print(\"Dataset with Missing Values:\")\n",
    "print(f\"Total records: {len(df_impute)}\")\n",
    "print(f\"Missing values: {df_impute['Age'].isna().sum()}\")\n",
    "print(f\"\\nFirst 20 values:\\n{df_impute.head(20)}\")\n",
    "\n",
    "# Imputation strategies\n",
    "mean_age = df_impute['Age'].mean()\n",
    "median_age = df_impute['Age'].median()\n",
    "\n",
    "# Create imputed versions\n",
    "df_impute['Age_Mean_Imputed'] = df_impute['Age'].fillna(mean_age)\n",
    "df_impute['Age_Median_Imputed'] = df_impute['Age'].fillna(median_age)\n",
    "\n",
    "print(f\"\\nImputation Statistics:\")\n",
    "print(f\"Mean for imputation: {mean_age:.2f}\")\n",
    "print(f\"Median for imputation: {median_age:.2f}\")\n",
    "print(f\"\\nSample of imputed data:\")\n",
    "print(df_impute[df_impute['Age'].isna()].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application 2: Feature Engineering - Customer Segmentation\n",
    "\n",
    "# Create customer transaction data\n",
    "np.random.seed(42)\n",
    "customer_data = {\n",
    "    'CustomerID': range(1, 101),\n",
    "    'Purchase1': np.random.uniform(10, 200, 100),\n",
    "    'Purchase2': np.random.uniform(10, 200, 100),\n",
    "    'Purchase3': np.random.uniform(10, 200, 100),\n",
    "    'Purchase4': np.random.uniform(10, 200, 100),\n",
    "    'Purchase5': np.random.uniform(10, 200, 100)\n",
    "}\n",
    "\n",
    "df_customers = pd.DataFrame(customer_data)\n",
    "\n",
    "# Feature engineering: Create aggregated features\n",
    "purchase_cols = ['Purchase1', 'Purchase2', 'Purchase3', 'Purchase4', 'Purchase5']\n",
    "\n",
    "df_customers['Avg_Purchase'] = df_customers[purchase_cols].mean(axis=1)\n",
    "df_customers['Median_Purchase'] = df_customers[purchase_cols].median(axis=1)\n",
    "df_customers['Total_Purchase'] = df_customers[purchase_cols].sum(axis=1)\n",
    "df_customers['Max_Purchase'] = df_customers[purchase_cols].max(axis=1)\n",
    "df_customers['Min_Purchase'] = df_customers[purchase_cols].min(axis=1)\n",
    "\n",
    "print(\"Customer Purchase Analysis with Engineered Features:\")\n",
    "print(\"=\"*80)\n",
    "print(df_customers[['CustomerID', 'Avg_Purchase', 'Median_Purchase', \n",
    "                     'Total_Purchase']].head(10))\n",
    "\n",
    "# Segment customers based on average purchase\n",
    "df_customers['Segment'] = pd.cut(df_customers['Avg_Purchase'], \n",
    "                                  bins=[0, 75, 125, 200],\n",
    "                                  labels=['Low Value', 'Medium Value', 'High Value'])\n",
    "\n",
    "print(\"\\nCustomer Segmentation:\")\n",
    "print(df_customers['Segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application 3: A/B Testing - Comparing Two Groups\n",
    "\n",
    "# Simulate A/B test: Two different website designs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Group A: Current design (control)\n",
    "time_on_site_A = np.random.normal(180, 40, 200)  # seconds\n",
    "\n",
    "# Group B: New design (treatment) - slightly better\n",
    "time_on_site_B = np.random.normal(195, 40, 200)  # seconds\n",
    "\n",
    "# Calculate central tendency for both groups\n",
    "mean_A = np.mean(time_on_site_A)\n",
    "median_A = np.median(time_on_site_A)\n",
    "mean_B = np.mean(time_on_site_B)\n",
    "median_B = np.median(time_on_site_B)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "ab_comparison = pd.DataFrame({\n",
    "    'Metric': ['Mean (seconds)', 'Median (seconds)', 'Sample Size'],\n",
    "    'Group A (Control)': [f\"{mean_A:.2f}\", f\"{median_A:.2f}\", len(time_on_site_A)],\n",
    "    'Group B (Treatment)': [f\"{mean_B:.2f}\", f\"{median_B:.2f}\", len(time_on_site_B)],\n",
    "    'Improvement': [\n",
    "        f\"{((mean_B/mean_A - 1) * 100):.2f}%\",\n",
    "        f\"{((median_B/median_A - 1) * 100):.2f}%\",\n",
    "        '-'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nA/B Testing Results: Time on Site\")\n",
    "print(\"=\"*80)\n",
    "print(ab_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(time_on_site_A, bins=30, color='lightcoral', alpha=0.7, \n",
    "             label='Group A', edgecolor='black')\n",
    "axes[0].axvline(mean_A, color='red', linestyle='--', linewidth=2, label=f'Mean A: {mean_A:.1f}s')\n",
    "axes[0].set_xlabel('Time on Site (seconds)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Group A: Current Design', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(time_on_site_B, bins=30, color='lightgreen', alpha=0.7, \n",
    "             label='Group B', edgecolor='black')\n",
    "axes[1].axvline(mean_B, color='green', linestyle='--', linewidth=2, label=f'Mean B: {mean_B:.1f}s')\n",
    "axes[1].set_xlabel('Time on Site (seconds)', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Group B: New Design', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConclusion: Group B shows {((mean_B/mean_A - 1) * 100):.2f}% improvement in average time on site!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application 4: Baseline Model using Central Tendency\n",
    "\n",
    "# Load a sample dataset: House prices prediction\n",
    "np.random.seed(42)\n",
    "actual_prices = np.random.normal(300000, 100000, 100)  # Actual house prices\n",
    "actual_prices = np.maximum(actual_prices, 100000)  # Ensure no negative prices\n",
    "\n",
    "# Baseline predictions using central tendency\n",
    "mean_baseline = np.full(len(actual_prices), np.mean(actual_prices))\n",
    "median_baseline = np.full(len(actual_prices), np.median(actual_prices))\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for each baseline\n",
    "mae_mean = np.mean(np.abs(actual_prices - mean_baseline))\n",
    "mae_median = np.mean(np.abs(actual_prices - median_baseline))\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for each baseline\n",
    "mse_mean = np.mean((actual_prices - mean_baseline) ** 2)\n",
    "mse_median = np.mean((actual_prices - median_baseline) ** 2)\n",
    "\n",
    "print(\"\\nBaseline Model Evaluation: House Price Prediction\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nMean-based Baseline:\")\n",
    "print(f\"  Prediction: ${np.mean(actual_prices):,.2f}\")\n",
    "print(f\"  MAE: ${mae_mean:,.2f}\")\n",
    "print(f\"  MSE: ${mse_mean:,.2f}\")\n",
    "\n",
    "print(f\"\\nMedian-based Baseline:\")\n",
    "print(f\"  Prediction: ${np.median(actual_prices):,.2f}\")\n",
    "print(f\"  MAE: ${mae_median:,.2f}\")\n",
    "print(f\"  MSE: ${mse_median:,.2f}\")\n",
    "\n",
    "print(f\"\\nNote: Mean minimizes MSE, Median minimizes MAE\")\n",
    "print(f\"Any ML model should beat these baseline errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application 5: Anomaly Detection using Central Tendency\n",
    "\n",
    "# Simulate server response times\n",
    "np.random.seed(42)\n",
    "normal_response_times = np.random.normal(200, 30, 95)  # milliseconds\n",
    "anomalies = np.array([500, 600, 550, 480, 520])  # Anomalous slow responses\n",
    "response_times = np.concatenate([normal_response_times, anomalies])\n",
    "\n",
    "# Calculate statistics\n",
    "mean_response = np.mean(response_times)\n",
    "median_response = np.median(response_times)\n",
    "std_response = np.std(response_times)\n",
    "\n",
    "# Define anomaly thresholds\n",
    "# Method 1: Mean ± 3*std (assumes normal distribution)\n",
    "threshold_mean = mean_response + 3 * std_response\n",
    "\n",
    "# Method 2: Median + 1.5*IQR (more robust)\n",
    "Q1 = np.percentile(response_times, 25)\n",
    "Q3 = np.percentile(response_times, 75)\n",
    "IQR = Q3 - Q1\n",
    "threshold_median = Q3 + 1.5 * IQR\n",
    "\n",
    "# Detect anomalies\n",
    "anomalies_detected_mean = response_times[response_times > threshold_mean]\n",
    "anomalies_detected_median = response_times[response_times > threshold_median]\n",
    "\n",
    "print(\"\\nAnomaly Detection: Server Response Times\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Mean Response Time: {mean_response:.2f} ms\")\n",
    "print(f\"Median Response Time: {median_response:.2f} ms\")\n",
    "print(f\"Standard Deviation: {std_response:.2f} ms\")\n",
    "\n",
    "print(f\"\\nMethod 1: Mean + 3*Std Threshold = {threshold_mean:.2f} ms\")\n",
    "print(f\"Anomalies Detected: {len(anomalies_detected_mean)}\")\n",
    "print(f\"Values: {anomalies_detected_mean}\")\n",
    "\n",
    "print(f\"\\nMethod 2: Median + 1.5*IQR Threshold = {threshold_median:.2f} ms\")\n",
    "print(f\"Anomalies Detected: {len(anomalies_detected_median)}\")\n",
    "print(f\"Values: {anomalies_detected_median}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(range(len(response_times)), response_times, \n",
    "            c=['red' if x > threshold_median else 'blue' for x in response_times],\n",
    "            alpha=0.6, s=50)\n",
    "plt.axhline(mean_response, color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {mean_response:.1f} ms')\n",
    "plt.axhline(median_response, color='orange', linestyle='--', linewidth=2, \n",
    "            label=f'Median: {median_response:.1f} ms')\n",
    "plt.axhline(threshold_median, color='red', linestyle=':', linewidth=2, \n",
    "            label=f'Anomaly Threshold: {threshold_median:.1f} ms')\n",
    "plt.xlabel('Request Number', fontsize=11)\n",
    "plt.ylabel('Response Time (ms)', fontsize=11)\n",
    "plt.title('Server Response Times with Anomaly Detection', fontsize=13, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Summary <a id=\"summary\"></a>\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Measures of Central Tendency** provide a single representative value for a dataset:\n",
    "   - **Mean**: Average of all values (best for symmetric data)\n",
    "   - **Median**: Middle value (best for skewed data or data with outliers)\n",
    "   - **Mode**: Most frequent value (best for categorical data)\n",
    "\n",
    "2. **Types of Means**:\n",
    "   - **Arithmetic Mean**: Standard average (use for most purposes)\n",
    "   - **Geometric Mean**: Use for growth rates, ratios, and multiplicative data\n",
    "   - **Harmonic Mean**: Use for rates, speeds, and reciprocal relationships\n",
    "\n",
    "3. **Outlier Sensitivity**:\n",
    "   - Mean is highly affected by outliers\n",
    "   - Median and mode are robust to outliers\n",
    "   - Choose median when data has extreme values\n",
    "\n",
    "4. **Skewness Relationships**:\n",
    "   - Symmetric: Mean = Median = Mode\n",
    "   - Right-Skewed: Mode < Median < Mean\n",
    "   - Left-Skewed: Mean < Median < Mode\n",
    "\n",
    "5. **Data Science Applications**:\n",
    "   - Data imputation and cleaning\n",
    "   - Feature engineering and aggregation\n",
    "   - Baseline model creation\n",
    "   - Anomaly detection\n",
    "   - A/B testing and comparison\n",
    "   - Business analytics and reporting\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - Always visualize your data before choosing a measure\n",
    "   - Check for outliers and skewness\n",
    "   - Report multiple measures when appropriate\n",
    "   - Understand your data's distribution\n",
    "   - Choose the measure that best represents your use case\n",
    "\n",
    "### When to Use Which Measure:\n",
    "\n",
    "| Situation | Best Measure | Reason |\n",
    "|-----------|--------------|--------|\n",
    "| Symmetric distribution | Mean | Uses all data points |\n",
    "| Skewed distribution | Median | Robust to skewness |\n",
    "| Data with outliers | Median | Not affected by extremes |\n",
    "| Categorical data | Mode | Only applicable measure |\n",
    "| Growth rates | Geometric Mean | Correct for compound growth |\n",
    "| Average speed/rates | Harmonic Mean | Correct for rate averaging |\n",
    "| Further calculations | Mean | Required for variance, etc. |\n",
    "| Income/House prices | Median | Typically right-skewed |\n",
    "| Test scores | Mean or Median | Depends on distribution |\n",
    "| Customer preferences | Mode | Finding most common choice |\n",
    "\n",
    "### Further Learning:\n",
    "\n",
    "- Explore **weighted mean** for data with different importance levels\n",
    "- Study **trimmed mean** (excluding extreme values)\n",
    "- Learn about **winsorized mean** (capping extreme values)\n",
    "- Understand **measures of dispersion** (variance, standard deviation)\n",
    "- Practice with **real-world datasets** from Kaggle or UCI ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comprehensive Example: Analyzing Real-World Dataset\n",
    "\n",
    "# Create a realistic dataset: E-commerce transaction amounts\n",
    "np.random.seed(42)\n",
    "\n",
    "# Mix of different customer segments\n",
    "small_purchases = np.random.gamma(shape=2, scale=15, size=600)  # Majority\n",
    "medium_purchases = np.random.gamma(shape=3, scale=30, size=300)\n",
    "large_purchases = np.random.gamma(shape=2, scale=100, size=80)\n",
    "very_large_purchases = np.random.uniform(500, 2000, 20)  # Outliers\n",
    "\n",
    "all_transactions = np.concatenate([small_purchases, medium_purchases, \n",
    "                                   large_purchases, very_large_purchases])\n",
    "\n",
    "# Calculate all measures\n",
    "arithmetic_mean = np.mean(all_transactions)\n",
    "geometric_mean_val = gmean(all_transactions)\n",
    "harmonic_mean_val = hmean(all_transactions)\n",
    "median_val = np.median(all_transactions)\n",
    "mode_val = stats.mode(all_transactions.round(), keepdims=True).mode[0]\n",
    "skewness_val = stats.skew(all_transactions)\n",
    "\n",
    "# Create summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"E-COMMERCE TRANSACTION ANALYSIS - COMPREHENSIVE REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total Transactions: {len(all_transactions):,}\")\n",
    "print(f\"  Transaction Range: ${all_transactions.min():.2f} - ${all_transactions.max():.2f}\")\n",
    "\n",
    "print(f\"\\nCentral Tendency Measures:\")\n",
    "print(f\"  Arithmetic Mean:    ${arithmetic_mean:.2f}\")\n",
    "print(f\"  Geometric Mean:     ${geometric_mean_val:.2f}\")\n",
    "print(f\"  Harmonic Mean:      ${harmonic_mean_val:.2f}\")\n",
    "print(f\"  Median:             ${median_val:.2f}\")\n",
    "print(f\"  Mode:               ${mode_val:.2f}\")\n",
    "\n",
    "print(f\"\\nDistribution Characteristics:\")\n",
    "print(f\"  Skewness:           {skewness_val:.2f} (Right-Skewed)\")\n",
    "print(f\"  Standard Deviation: ${np.std(all_transactions):.2f}\")\n",
    "\n",
    "# Percentiles\n",
    "p25 = np.percentile(all_transactions, 25)\n",
    "p75 = np.percentile(all_transactions, 75)\n",
    "p90 = np.percentile(all_transactions, 90)\n",
    "\n",
    "print(f\"\\nPercentiles:\")\n",
    "print(f\"  25th Percentile (Q1): ${p25:.2f}\")\n",
    "print(f\"  50th Percentile (Median): ${median_val:.2f}\")\n",
    "print(f\"  75th Percentile (Q3): ${p75:.2f}\")\n",
    "print(f\"  90th Percentile: ${p90:.2f}\")\n",
    "\n",
    "print(f\"\\nBusiness Insights:\")\n",
    "print(f\"  - Typical transaction (Median): ${median_val:.2f}\")\n",
    "print(f\"  - Average transaction (Mean): ${arithmetic_mean:.2f}\")\n",
    "print(f\"  - Mean is {((arithmetic_mean/median_val - 1)*100):.1f}% higher than median\")\n",
    "print(f\"    (indicates presence of high-value outliers)\")\n",
    "print(f\"  - 50% of transactions are below ${median_val:.2f}\")\n",
    "print(f\"  - 10% of transactions exceed ${p90:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Visualization\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Histogram with all measures\n",
    "axes[0, 0].hist(all_transactions, bins=60, color='steelblue', \n",
    "                edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(arithmetic_mean, color='red', linestyle='--', linewidth=2.5, \n",
    "                   label=f'Mean: ${arithmetic_mean:.2f}')\n",
    "axes[0, 0].axvline(median_val, color='green', linestyle='--', linewidth=2.5, \n",
    "                   label=f'Median: ${median_val:.2f}')\n",
    "axes[0, 0].set_xlabel('Transaction Amount ($)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 0].set_title('Distribution of Transaction Amounts', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Box plot\n",
    "axes[0, 1].boxplot(all_transactions, vert=False, widths=0.7)\n",
    "axes[0, 1].axvline(arithmetic_mean, color='red', linestyle='--', linewidth=2, \n",
    "                   label='Mean')\n",
    "axes[0, 1].axvline(median_val, color='green', linestyle='--', linewidth=2, \n",
    "                   label='Median')\n",
    "axes[0, 1].set_xlabel('Transaction Amount ($)', fontsize=11)\n",
    "axes[0, 1].set_title('Box Plot (Outliers Visible)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Comparison of different means\n",
    "means_comparison = [harmonic_mean_val, geometric_mean_val, arithmetic_mean, median_val]\n",
    "means_labels = ['Harmonic\\nMean', 'Geometric\\nMean', 'Arithmetic\\nMean', 'Median']\n",
    "colors_means = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "\n",
    "bars = axes[1, 0].bar(means_labels, means_comparison, color=colors_means, \n",
    "                      alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Value ($)', fontsize=11)\n",
    "axes[1, 0].set_title('Comparison of Central Tendency Measures', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'${height:.2f}', ha='center', va='bottom', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 4: Cumulative Distribution\n",
    "sorted_transactions = np.sort(all_transactions)\n",
    "cumulative = np.arange(1, len(sorted_transactions) + 1) / len(sorted_transactions) * 100\n",
    "\n",
    "axes[1, 1].plot(sorted_transactions, cumulative, color='purple', linewidth=2)\n",
    "axes[1, 1].axvline(median_val, color='green', linestyle='--', linewidth=2, \n",
    "                   label=f'Median: ${median_val:.2f}')\n",
    "axes[1, 1].axhline(50, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Transaction Amount ($)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Cumulative Percentage (%)', fontsize=11)\n",
    "axes[1, 1].set_title('Cumulative Distribution Function', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization Complete!\")\n",
    "print(\"This comprehensive analysis demonstrates all key concepts of central tendency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your understanding:\n",
    "\n",
    "1. **Calculate all measures** for a dataset of your choice (use pandas to load a CSV)\n",
    "2. **Identify outliers** in a dataset and compare mean vs median\n",
    "3. **Create visualizations** showing the relationship between skewness and central tendency\n",
    "4. **Implement imputation** using different central tendency measures\n",
    "5. **Compare geometric vs arithmetic mean** for investment returns\n",
    "6. **Build a baseline model** using central tendency for a regression problem\n",
    "7. **Analyze a real dataset** from Kaggle and report all central tendency measures\n",
    "\n",
    "Remember: The best measure of central tendency depends on your data characteristics and analysis goals!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
