{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Files in Python\n",
    "\n",
    "Beyond basic file I/O operations, Python provides powerful tools for managing files and directories, working with different file formats, and performing advanced file operations. This notebook covers practical file handling techniques you'll use in real-world projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Working with File Paths](#paths)\n",
    "3. [File and Directory Operations](#operations)\n",
    "4. [Checking File Properties](#properties)\n",
    "5. [Directory Traversal](#traversal)\n",
    "6. [Working with JSON Files](#json)\n",
    "7. [Working with CSV Files](#csv)\n",
    "8. [Working with Temporary Files](#temp)\n",
    "9. [File Copying and Moving](#copy-move)\n",
    "10. [Advanced File Patterns](#advanced)\n",
    "11. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id='introduction'></a>\n",
    "\n",
    "When working with files in Python, you often need to:\n",
    "- Manage file paths across different operating systems\n",
    "- Create, delete, rename, and move files\n",
    "- Check if files or directories exist\n",
    "- Work with different file formats (JSON, CSV, etc.)\n",
    "- Navigate directory structures\n",
    "- Handle file operations safely\n",
    "\n",
    "**Key Modules:**\n",
    "- **`os`**: Operating system interfaces\n",
    "- **`os.path`**: Path manipulations (older style)\n",
    "- **`pathlib`**: Object-oriented path handling (modern)\n",
    "- **`shutil`**: High-level file operations\n",
    "- **`json`**: JSON file handling\n",
    "- **`csv`**: CSV file handling\n",
    "- **`tempfile`**: Temporary file operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with File Paths <a id='paths'></a>\n",
    "\n",
    "Python provides two main ways to work with file paths: `os.path` (classic) and `pathlib` (modern, object-oriented)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using os.path (Classic Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)\n",
    "\n",
    "# Joining paths (works across OS)\n",
    "file_path = os.path.join(current_dir, 'data', 'file.txt')\n",
    "print(\"\\nJoined path:\", file_path)\n",
    "\n",
    "# Path components\n",
    "print(\"\\nPath components:\")\n",
    "print(\"Directory name:\", os.path.dirname(file_path))\n",
    "print(\"Base name:\", os.path.basename(file_path))\n",
    "print(\"Split:\", os.path.split(file_path))\n",
    "\n",
    "# File name and extension\n",
    "filename = \"document.pdf\"\n",
    "name, ext = os.path.splitext(filename)\n",
    "print(\"\\nFilename:\", name)\n",
    "print(\"Extension:\", ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pathlib (Modern Approach - Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Current working directory\n",
    "current_dir = Path.cwd()\n",
    "print(\"Current directory:\", current_dir)\n",
    "\n",
    "# Joining paths using / operator\n",
    "file_path = current_dir / 'data' / 'file.txt'\n",
    "print(\"\\nJoined path:\", file_path)\n",
    "\n",
    "# Path components (as properties)\n",
    "print(\"\\nPath components:\")\n",
    "print(\"Parent:\", file_path.parent)\n",
    "print(\"Name:\", file_path.name)\n",
    "print(\"Stem (without extension):\", file_path.stem)\n",
    "print(\"Suffix (extension):\", file_path.suffix)\n",
    "print(\"Parts:\", file_path.parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More pathlib features\n",
    "from pathlib import Path\n",
    "\n",
    "# Create path objects\n",
    "path = Path('example.txt')\n",
    "\n",
    "# Absolute path\n",
    "abs_path = path.absolute()\n",
    "print(\"Absolute path:\", abs_path)\n",
    "\n",
    "# Home directory\n",
    "home = Path.home()\n",
    "print(\"\\nHome directory:\", home)\n",
    "\n",
    "# Changing extension\n",
    "new_path = path.with_suffix('.pdf')\n",
    "print(\"\\nPath with new extension:\", new_path)\n",
    "\n",
    "# Changing name\n",
    "new_path = path.with_name('new_example.txt')\n",
    "print(\"Path with new name:\", new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. File and Directory Operations <a id='operations'></a>\n",
    "\n",
    "Creating, deleting, renaming, and managing files and directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Using os\n",
    "if not os.path.exists('test_dir'):\n",
    "    os.mkdir('test_dir')\n",
    "    print(\"Directory 'test_dir' created using os\")\n",
    "\n",
    "# Create nested directories\n",
    "if not os.path.exists('parent/child/grandchild'):\n",
    "    os.makedirs('parent/child/grandchild')\n",
    "    print(\"Nested directories created using os\")\n",
    "\n",
    "# Using pathlib (recommended)\n",
    "Path('test_dir_pathlib').mkdir(exist_ok=True)\n",
    "print(\"\\nDirectory 'test_dir_pathlib' created using pathlib\")\n",
    "\n",
    "# Create nested directories with pathlib\n",
    "Path('parent2/child2/grandchild2').mkdir(parents=True, exist_ok=True)\n",
    "print(\"Nested directories created using pathlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Files and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create test file\n",
    "test_file = Path('delete_me.txt')\n",
    "test_file.write_text('This file will be deleted')\n",
    "\n",
    "# Delete file using os\n",
    "if os.path.exists('delete_me.txt'):\n",
    "    os.remove('delete_me.txt')\n",
    "    print(\"File deleted using os.remove()\")\n",
    "\n",
    "# Delete file using pathlib\n",
    "test_file2 = Path('delete_me2.txt')\n",
    "test_file2.write_text('This file will also be deleted')\n",
    "if test_file2.exists():\n",
    "    test_file2.unlink()\n",
    "    print(\"File deleted using pathlib.unlink()\")\n",
    "\n",
    "# Delete empty directory\n",
    "empty_dir = Path('empty_dir')\n",
    "empty_dir.mkdir(exist_ok=True)\n",
    "empty_dir.rmdir()\n",
    "print(\"\\nEmpty directory deleted\")\n",
    "\n",
    "# Delete directory with contents using shutil\n",
    "Path('temp_dir').mkdir(exist_ok=True)\n",
    "Path('temp_dir/file.txt').write_text('content')\n",
    "shutil.rmtree('temp_dir')\n",
    "print(\"Directory with contents deleted using shutil.rmtree()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and Moving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create test file\n",
    "old_name = Path('old_name.txt')\n",
    "old_name.write_text('Content')\n",
    "\n",
    "# Rename using os\n",
    "os.rename('old_name.txt', 'new_name.txt')\n",
    "print(\"File renamed using os.rename()\")\n",
    "\n",
    "# Rename using pathlib\n",
    "old_path = Path('new_name.txt')\n",
    "new_path = Path('final_name.txt')\n",
    "old_path.rename(new_path)\n",
    "print(\"File renamed using pathlib.rename()\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nFinal file exists:\", new_path.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Checking File Properties <a id='properties'></a>\n",
    "\n",
    "Get information about files and directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Create a sample file\n",
    "sample_file = Path('sample_properties.txt')\n",
    "sample_file.write_text('Hello, World!\\nThis is a test file.')\n",
    "\n",
    "# Check existence\n",
    "print(\"File exists:\", sample_file.exists())\n",
    "print(\"Is file:\", sample_file.is_file())\n",
    "print(\"Is directory:\", sample_file.is_dir())\n",
    "\n",
    "# File size\n",
    "print(\"\\nFile size (bytes):\", sample_file.stat().st_size)\n",
    "\n",
    "# Modification time\n",
    "mtime = sample_file.stat().st_mtime\n",
    "print(\"\\nModification time (timestamp):\", mtime)\n",
    "print(\"Modification time (readable):\", time.ctime(mtime))\n",
    "\n",
    "# Access and creation time\n",
    "print(\"\\nAccess time:\", time.ctime(sample_file.stat().st_atime))\n",
    "print(\"Creation time:\", time.ctime(sample_file.stat().st_ctime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files and directories in current directory\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path('.')\n",
    "\n",
    "print(\"Files in current directory:\")\n",
    "for item in current_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        print(f\"  File: {item.name} ({item.stat().st_size} bytes)\")\n",
    "\n",
    "print(\"\\nDirectories in current directory:\")\n",
    "for item in current_dir.iterdir():\n",
    "    if item.is_dir():\n",
    "        print(f\"  Dir: {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Directory Traversal <a id='traversal'></a>\n",
    "\n",
    "Navigate through directory structures and find files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample directory structure\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup test structure\n",
    "base = Path('test_structure')\n",
    "base.mkdir(exist_ok=True)\n",
    "(base / 'folder1').mkdir(exist_ok=True)\n",
    "(base / 'folder2').mkdir(exist_ok=True)\n",
    "(base / 'folder1' / 'subfolder').mkdir(exist_ok=True)\n",
    "\n",
    "# Create some files\n",
    "(base / 'file1.txt').write_text('content1')\n",
    "(base / 'file2.py').write_text('print(\"hello\")')\n",
    "(base / 'folder1' / 'file3.txt').write_text('content3')\n",
    "(base / 'folder1' / 'subfolder' / 'file4.py').write_text('# comment')\n",
    "(base / 'folder2' / 'file5.txt').write_text('content5')\n",
    "\n",
    "print(\"Test structure created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using os.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Walking through test_structure using os.walk():\")\n",
    "for root, dirs, files in os.walk('test_structure'):\n",
    "    print(f\"\\nDirectory: {root}\")\n",
    "    print(f\"  Subdirectories: {dirs}\")\n",
    "    print(f\"  Files: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pathlib (Modern Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Find all files recursively\n",
    "print(\"All files (recursive):\")\n",
    "for file_path in Path('test_structure').rglob('*'):\n",
    "    if file_path.is_file():\n",
    "        print(f\"  {file_path}\")\n",
    "\n",
    "# Find specific file types\n",
    "print(\"\\nAll .txt files:\")\n",
    "for txt_file in Path('test_structure').rglob('*.txt'):\n",
    "    print(f\"  {txt_file}\")\n",
    "\n",
    "print(\"\\nAll .py files:\")\n",
    "for py_file in Path('test_structure').rglob('*.py'):\n",
    "    print(f\"  {py_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Working with JSON Files <a id='json'></a>\n",
    "\n",
    "JSON (JavaScript Object Notation) is a popular data format for storing and exchanging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Creating Python data\n",
    "data = {\n",
    "    'name': 'Alice',\n",
    "    'age': 30,\n",
    "    'city': 'New York',\n",
    "    'skills': ['Python', 'JavaScript', 'SQL'],\n",
    "    'active': True\n",
    "}\n",
    "\n",
    "# Writing JSON to file\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"JSON data written to file\")\n",
    "\n",
    "# Reading JSON from file\n",
    "with open('data.json', 'r') as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "print(\"\\nLoaded data:\")\n",
    "print(loaded_data)\n",
    "print(f\"\\nName: {loaded_data['name']}\")\n",
    "print(f\"Skills: {', '.join(loaded_data['skills'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with JSON strings (not files)\n",
    "import json\n",
    "\n",
    "# Python object to JSON string\n",
    "person = {'name': 'Bob', 'age': 25}\n",
    "json_string = json.dumps(person, indent=2)\n",
    "print(\"JSON string:\")\n",
    "print(json_string)\n",
    "\n",
    "# JSON string to Python object\n",
    "json_str = '{\"product\": \"Laptop\", \"price\": 999.99}'\n",
    "product = json.loads(json_str)\n",
    "print(\"\\nParsed Python object:\")\n",
    "print(f\"Product: {product['product']}\")\n",
    "print(f\"Price: ${product['price']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with complex JSON data\n",
    "import json\n",
    "\n",
    "# Multiple records\n",
    "users = [\n",
    "    {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'},\n",
    "    {'id': 2, 'name': 'Bob', 'email': 'bob@example.com'},\n",
    "    {'id': 3, 'name': 'Charlie', 'email': 'charlie@example.com'}\n",
    "]\n",
    "\n",
    "# Save to JSON\n",
    "with open('users.json', 'w') as f:\n",
    "    json.dump(users, f, indent=2)\n",
    "\n",
    "# Load and filter\n",
    "with open('users.json', 'r') as f:\n",
    "    all_users = json.load(f)\n",
    "\n",
    "print(\"All users:\")\n",
    "for user in all_users:\n",
    "    print(f\"  {user['id']}: {user['name']} ({user['email']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Working with CSV Files <a id='csv'></a>\n",
    "\n",
    "CSV (Comma-Separated Values) is a common format for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Writing CSV file\n",
    "data = [\n",
    "    ['Name', 'Age', 'City'],\n",
    "    ['Alice', 30, 'New York'],\n",
    "    ['Bob', 25, 'Los Angeles'],\n",
    "    ['Charlie', 35, 'Chicago']\n",
    "]\n",
    "\n",
    "with open('people.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"CSV file created\")\n",
    "\n",
    "# Reading CSV file\n",
    "print(\"\\nReading CSV file:\")\n",
    "with open('people.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with CSV using DictReader/DictWriter\n",
    "import csv\n",
    "\n",
    "# Writing with DictWriter\n",
    "employees = [\n",
    "    {'name': 'Alice', 'position': 'Developer', 'salary': 80000},\n",
    "    {'name': 'Bob', 'position': 'Designer', 'salary': 70000},\n",
    "    {'name': 'Charlie', 'position': 'Manager', 'salary': 90000}\n",
    "]\n",
    "\n",
    "with open('employees.csv', 'w', newline='') as f:\n",
    "    fieldnames = ['name', 'position', 'salary']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    writer.writerows(employees)\n",
    "\n",
    "print(\"Employees CSV created\")\n",
    "\n",
    "# Reading with DictReader\n",
    "print(\"\\nReading employees:\")\n",
    "with open('employees.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        print(f\"{row['name']}: {row['position']} - ${row['salary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Working with Temporary Files <a id='temp'></a>\n",
    "\n",
    "Temporary files are useful for testing and storing data that doesn't need to persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Create temporary file (automatically deleted)\n",
    "with tempfile.TemporaryFile(mode='w+') as f:\n",
    "    # Write to temp file\n",
    "    f.write('This is temporary data\\n')\n",
    "    f.write('It will be deleted automatically')\n",
    "    \n",
    "    # Read from temp file\n",
    "    f.seek(0)\n",
    "    content = f.read()\n",
    "    print(\"Temp file content:\")\n",
    "    print(content)\n",
    "\n",
    "print(\"\\nTemp file has been automatically deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create named temporary file\n",
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as f:\n",
    "    print(f\"Temp file name: {f.name}\")\n",
    "    f.write('Named temporary file')\n",
    "    temp_name = f.name\n",
    "\n",
    "# File still exists after with block (delete=False)\n",
    "from pathlib import Path\n",
    "print(f\"\\nFile exists: {Path(temp_name).exists()}\")\n",
    "\n",
    "# Clean up manually\n",
    "Path(temp_name).unlink()\n",
    "print(f\"File exists after cleanup: {Path(temp_name).exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    print(f\"Temp directory: {temp_dir}\")\n",
    "    \n",
    "    # Create files in temp directory\n",
    "    temp_file = Path(temp_dir) / 'test.txt'\n",
    "    temp_file.write_text('Temporary content')\n",
    "    \n",
    "    print(f\"Temp file exists: {temp_file.exists()}\")\n",
    "    print(f\"Content: {temp_file.read_text()}\")\n",
    "\n",
    "print(\"\\nTemp directory and all contents deleted automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. File Copying and Moving <a id='copy-move'></a>\n",
    "\n",
    "Use the `shutil` module for high-level file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create source file\n",
    "source = Path('source_file.txt')\n",
    "source.write_text('This is the source file content')\n",
    "\n",
    "# Copy file\n",
    "destination = Path('copied_file.txt')\n",
    "shutil.copy(source, destination)\n",
    "print(f\"File copied: {destination.exists()}\")\n",
    "\n",
    "# Copy file with metadata\n",
    "destination2 = Path('copied_with_metadata.txt')\n",
    "shutil.copy2(source, destination2)\n",
    "print(f\"File copied with metadata: {destination2.exists()}\")\n",
    "\n",
    "# Verify content\n",
    "print(f\"\\nOriginal: {source.read_text()}\")\n",
    "print(f\"Copy: {destination.read_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy entire directory tree\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create source directory structure\n",
    "source_dir = Path('source_dir')\n",
    "source_dir.mkdir(exist_ok=True)\n",
    "(source_dir / 'file1.txt').write_text('File 1')\n",
    "(source_dir / 'file2.txt').write_text('File 2')\n",
    "(source_dir / 'subdir').mkdir(exist_ok=True)\n",
    "(source_dir / 'subdir' / 'file3.txt').write_text('File 3')\n",
    "\n",
    "# Copy entire tree\n",
    "dest_dir = Path('destination_dir')\n",
    "if dest_dir.exists():\n",
    "    shutil.rmtree(dest_dir)\n",
    "shutil.copytree(source_dir, dest_dir)\n",
    "\n",
    "print(\"Directory tree copied\")\n",
    "print(\"\\nContents of destination:\")\n",
    "for item in dest_dir.rglob('*'):\n",
    "    if item.is_file():\n",
    "        print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files and directories\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create file to move\n",
    "move_source = Path('move_me.txt')\n",
    "move_source.write_text('Move this file')\n",
    "\n",
    "# Move file\n",
    "moved_file = shutil.move(str(move_source), 'moved_file.txt')\n",
    "print(f\"File moved to: {moved_file}\")\n",
    "print(f\"Original exists: {move_source.exists()}\")\n",
    "print(f\"New location exists: {Path(moved_file).exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced File Patterns <a id='advanced'></a>\n",
    "\n",
    "Practical patterns for common file operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 1: Safe File Writing (Atomic Write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def atomic_write(filename, content):\n",
    "    \"\"\"\n",
    "    Safely write to file using temporary file\n",
    "    Ensures file is not corrupted if write fails\n",
    "    \"\"\"\n",
    "    filepath = Path(filename)\n",
    "    \n",
    "    # Write to temporary file first\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, \n",
    "                                     dir=filepath.parent) as tmp:\n",
    "        tmp.write(content)\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    # Move temp file to target (atomic operation)\n",
    "    shutil.move(tmp_path, filepath)\n",
    "    print(f\"File written safely to {filename}\")\n",
    "\n",
    "# Test atomic write\n",
    "atomic_write('important_data.txt', 'Critical data that must be preserved')\n",
    "print(f\"Content: {Path('important_data.txt').read_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Backing Up Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def backup_file(filename):\n",
    "    \"\"\"Create timestamped backup of file\"\"\"\n",
    "    filepath = Path(filename)\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        print(f\"File {filename} doesn't exist\")\n",
    "        return None\n",
    "    \n",
    "    # Create backup filename with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    backup_name = f\"{filepath.stem}_{timestamp}{filepath.suffix}\"\n",
    "    backup_path = filepath.parent / backup_name\n",
    "    \n",
    "    # Copy file\n",
    "    shutil.copy2(filepath, backup_path)\n",
    "    print(f\"Backup created: {backup_path}\")\n",
    "    return backup_path\n",
    "\n",
    "# Test backup\n",
    "test_file = Path('backup_test.txt')\n",
    "test_file.write_text('Important data v1')\n",
    "backup_path = backup_file('backup_test.txt')\n",
    "\n",
    "# Modify original\n",
    "test_file.write_text('Important data v2')\n",
    "\n",
    "print(f\"\\nOriginal: {test_file.read_text()}\")\n",
    "print(f\"Backup: {backup_path.read_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Processing Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def process_text_files(directory, processor_func):\n",
    "    \"\"\"\n",
    "    Apply a processing function to all text files in directory\n",
    "    \"\"\"\n",
    "    processed_count = 0\n",
    "    \n",
    "    for txt_file in Path(directory).rglob('*.txt'):\n",
    "        try:\n",
    "            content = txt_file.read_text()\n",
    "            processed = processor_func(content)\n",
    "            txt_file.write_text(processed)\n",
    "            processed_count += 1\n",
    "            print(f\"Processed: {txt_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {txt_file}: {e}\")\n",
    "    \n",
    "    return processed_count\n",
    "\n",
    "# Example: Convert all text files to uppercase\n",
    "# Create test files\n",
    "test_dir = Path('process_test')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "(test_dir / 'file1.txt').write_text('hello world')\n",
    "(test_dir / 'file2.txt').write_text('python programming')\n",
    "\n",
    "# Process files\n",
    "count = process_text_files('process_test', str.upper)\n",
    "print(f\"\\n{count} files processed\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nResults:\")\n",
    "for f in test_dir.glob('*.txt'):\n",
    "    print(f\"{f.name}: {f.read_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 4: Reading Large Files in Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_chunks(filename, chunk_size=1024):\n",
    "    \"\"\"\n",
    "    Read large file in chunks (memory efficient)\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "# Create a test file\n",
    "large_file = Path('large_file.txt')\n",
    "large_file.write_text('A' * 5000 + 'B' * 5000)\n",
    "\n",
    "# Read in chunks\n",
    "print(\"Reading file in chunks:\")\n",
    "chunk_count = 0\n",
    "for chunk in read_in_chunks('large_file.txt', chunk_size=100):\n",
    "    chunk_count += 1\n",
    "    # Process chunk here\n",
    "    if chunk_count <= 3:\n",
    "        print(f\"Chunk {chunk_count}: {len(chunk)} characters, starts with '{chunk[:10]}'\")\n",
    "\n",
    "print(f\"\\nTotal chunks read: {chunk_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 5: File Locking (Safe Concurrent Access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcntl\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def write_with_lock(filename, content):\n",
    "    \"\"\"\n",
    "    Write to file with exclusive lock (Unix/Linux only)\n",
    "    Prevents concurrent writes from corrupting data\n",
    "    \"\"\"\n",
    "    with open(filename, 'a') as f:\n",
    "        try:\n",
    "            # Acquire exclusive lock\n",
    "            fcntl.flock(f.fileno(), fcntl.LOCK_EX)\n",
    "            f.write(content + '\\n')\n",
    "            print(f\"Written: {content}\")\n",
    "        finally:\n",
    "            # Release lock\n",
    "            fcntl.flock(f.fileno(), fcntl.LOCK_UN)\n",
    "\n",
    "# Note: fcntl is Unix/Linux only\n",
    "# For Windows, use msvcrt module or file-based locking\n",
    "print(\"Note: File locking example (Unix/Linux specific)\")\n",
    "print(\"On Windows, use msvcrt module for similar functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary <a id='summary'></a>\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **File Paths:**\n",
    "   - Use `pathlib.Path` for modern, cross-platform path handling\n",
    "   - `os.path` is older but still widely used\n",
    "   - Always use Path objects or os.path.join() for cross-platform compatibility\n",
    "\n",
    "2. **Directory Operations:**\n",
    "   - `mkdir()`: Create directory\n",
    "   - `makedirs()`/`mkdir(parents=True)`: Create nested directories\n",
    "   - `rmdir()`: Remove empty directory\n",
    "   - `shutil.rmtree()`: Remove directory tree\n",
    "\n",
    "3. **File Operations:**\n",
    "   - `rename()`: Rename/move files\n",
    "   - `unlink()`/`remove()`: Delete files\n",
    "   - Always check `exists()` before operations\n",
    "\n",
    "4. **File Properties:**\n",
    "   - `exists()`: Check existence\n",
    "   - `is_file()`/`is_dir()`: Check type\n",
    "   - `stat()`: Get detailed file information\n",
    "   - `iterdir()`: List directory contents\n",
    "\n",
    "5. **Directory Traversal:**\n",
    "   - `os.walk()`: Classic approach\n",
    "   - `Path.rglob()`: Modern, pattern-based (recommended)\n",
    "   - `Path.glob()`: Non-recursive pattern matching\n",
    "\n",
    "6. **JSON Files:**\n",
    "   - `json.dump()`: Write Python objects to JSON file\n",
    "   - `json.load()`: Read JSON file to Python objects\n",
    "   - `json.dumps()`/`json.loads()`: Work with JSON strings\n",
    "   - Use `indent` parameter for readable formatting\n",
    "\n",
    "7. **CSV Files:**\n",
    "   - `csv.reader()`/`csv.writer()`: Basic CSV operations\n",
    "   - `csv.DictReader()`/`csv.DictWriter()`: Work with dictionaries (recommended)\n",
    "   - Always use `newline=''` when opening CSV files\n",
    "\n",
    "8. **Temporary Files:**\n",
    "   - `TemporaryFile()`: Unnamed, auto-deleted\n",
    "   - `NamedTemporaryFile()`: Named, optionally auto-deleted\n",
    "   - `TemporaryDirectory()`: Temp directory with auto-cleanup\n",
    "\n",
    "9. **Copying and Moving:**\n",
    "   - `shutil.copy()`: Copy file\n",
    "   - `shutil.copy2()`: Copy with metadata\n",
    "   - `shutil.copytree()`: Copy directory tree\n",
    "   - `shutil.move()`: Move file or directory\n",
    "\n",
    "10. **Best Practices:**\n",
    "    - Always use context managers (`with` statement)\n",
    "    - Check file existence before operations\n",
    "    - Handle exceptions appropriately\n",
    "    - Use atomic writes for critical data\n",
    "    - Create backups before modifying important files\n",
    "    - Process large files in chunks\n",
    "    - Specify encoding explicitly for text files\n",
    "\n",
    "### Common Patterns:\n",
    "\n",
    "```python\n",
    "# Pathlib for file operations\n",
    "from pathlib import Path\n",
    "file = Path('data') / 'file.txt'\n",
    "if file.exists():\n",
    "    content = file.read_text()\n",
    "\n",
    "# JSON operations\n",
    "import json\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "# CSV operations\n",
    "import csv\n",
    "with open('data.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "# Directory traversal\n",
    "for txt_file in Path('.').rglob('*.txt'):\n",
    "    process(txt_file)\n",
    "\n",
    "# Safe file operations\n",
    "import shutil\n",
    "shutil.copy2(source, dest)  # Copy with metadata\n",
    "```\n",
    "\n",
    "### Remember:\n",
    "- Modern Python prefers `pathlib` over `os.path`\n",
    "- Always handle file operations with proper error handling\n",
    "- Use appropriate file formats (JSON for structured data, CSV for tabular data)\n",
    "- Consider using temporary files for sensitive or temporary data\n",
    "- Back up important files before modification\n",
    "- Use `shutil` for high-level file operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
