{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "719abfa7",
      "metadata": {},
      "source": [
        "# Handling Outliers Using Python\n",
        "\n",
        "## Introduction\n",
        "\n",
        "**Outliers** are data points that significantly differ from other observations in the dataset. They can be unusually high or low values that don't follow the general pattern of the data.\n",
        "\n",
        "### What are Outliers?\n",
        "\n",
        "An outlier is an observation that lies an abnormal distance from other values in a dataset. For example:\n",
        "- In a dataset of house prices mostly between $200K-$500K, a $5M mansion is an outlier\n",
        "- In student test scores mostly between 60-95, a score of 15 is an outlier\n",
        "- In temperature readings between 20-30¬∞C, a value of 100¬∞C is likely an error\n",
        "\n",
        "### Types of Outliers\n",
        "\n",
        "**1. Univariate Outliers**\n",
        "   - Extreme values in a single variable\n",
        "   - Example: Age = 200 years in a health dataset\n",
        "\n",
        "**2. Multivariate Outliers**\n",
        "   - Normal individually but unusual in combination\n",
        "   - Example: Age = 5 years with Income = $200K\n",
        "\n",
        "**3. Point Outliers**\n",
        "   - Individual data points far from others\n",
        "   - Most common type\n",
        "\n",
        "**4. Contextual Outliers**\n",
        "   - Outliers in specific contexts\n",
        "   - Example: 30¬∞C is normal in summer but outlier in winter\n",
        "\n",
        "**5. Collective Outliers**\n",
        "   - Collection of points that are outliers together\n",
        "   - Example: Sudden spike in website traffic\n",
        "\n",
        "### Causes of Outliers\n",
        "\n",
        "**Natural Outliers (Legitimate):**\n",
        "- Rare events (lottery winners, natural disasters)\n",
        "- Exceptional performance (Olympic athletes)\n",
        "- Genuine variability in data\n",
        "\n",
        "**Artificial Outliers (Errors):**\n",
        "- Data entry errors (typos: 150 instead of 15.0)\n",
        "- Measurement errors (faulty sensors)\n",
        "- Processing errors (unit conversions gone wrong)\n",
        "- Sampling errors (wrong population sampled)\n",
        "\n",
        "### Impact of Outliers\n",
        "\n",
        "**Negative Effects:**\n",
        "- Skew statistical measures (mean, standard deviation)\n",
        "- Violate assumptions of statistical tests\n",
        "- Reduce model accuracy\n",
        "- Increase error in predictions\n",
        "- Mask true patterns in data\n",
        "\n",
        "**Positive Effects:**\n",
        "- Can represent important rare events (fraud detection)\n",
        "- May indicate new discoveries or patterns\n",
        "- Sometimes the most interesting data points\n",
        "\n",
        "### When to Remove vs Keep Outliers\n",
        "\n",
        "**Remove When:**\n",
        "- Data entry errors confirmed\n",
        "- Measurement errors identified\n",
        "- Outside the scope of analysis\n",
        "- Breaking model assumptions\n",
        "\n",
        "**Keep When:**\n",
        "- Natural variability in data\n",
        "- Rare but legitimate events\n",
        "- Target of analysis (fraud, anomalies)\n",
        "- Domain knowledge confirms validity\n",
        "\n",
        "Let's explore various methods to detect and handle outliers!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad5584e",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries and Create Dataset with Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd542c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create a dataset with intentional outliers\n",
        "# Normal data\n",
        "normal_data = np.random.normal(100, 15, 200)\n",
        "\n",
        "# Add outliers\n",
        "outliers = np.array([50, 45, 180, 190, 200, 35, 185, 195])\n",
        "data_with_outliers = np.concatenate([normal_data, outliers])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Values': data_with_outliers,\n",
        "    'Age': np.concatenate([np.random.randint(20, 60, 200), np.array([5, 95, 3, 100, 102, 8, 98, 105])]),\n",
        "    'Salary': np.concatenate([np.random.normal(50000, 10000, 200), \n",
        "                              np.array([10000, 5000, 150000, 180000, 200000, 8000, 160000, 190000])])\n",
        "})\n",
        "\n",
        "print(\"=\" * 100)\n",
        "print(\"DATASET WITH OUTLIERS CREATED\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"\\nDataset Shape: {df.shape}\")\n",
        "print(f\"\\nFirst 10 rows:\")\n",
        "print(df.head(10))\n",
        "print(f\"\\nLast 10 rows (includes outliers):\")\n",
        "print(df.tail(10))\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"BASIC STATISTICS:\")\n",
        "print(\"-\" * 100)\n",
        "print(df.describe())\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Dataset Overview: Visualizing Outliers', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Histograms\n",
        "for idx, col in enumerate(['Values', 'Age', 'Salary']):\n",
        "    axes[0, idx].hist(df[col], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, idx].set_xlabel(col, fontweight='bold')\n",
        "    axes[0, idx].set_ylabel('Frequency', fontweight='bold')\n",
        "    axes[0, idx].set_title(f'{col} Distribution', fontweight='bold')\n",
        "    axes[0, idx].grid(alpha=0.3)\n",
        "    axes[0, idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
        "    axes[0, idx].axvline(df[col].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
        "    axes[0, idx].legend()\n",
        "\n",
        "# Box plots\n",
        "for idx, col in enumerate(['Values', 'Age', 'Salary']):\n",
        "    box = axes[1, idx].boxplot(df[col], vert=True, patch_artist=True)\n",
        "    box['boxes'][0].set_facecolor('lightcoral')\n",
        "    axes[1, idx].set_ylabel(col, fontweight='bold')\n",
        "    axes[1, idx].set_title(f'{col} Box Plot', fontweight='bold')\n",
        "    axes[1, idx].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"üëÅÔ∏è VISUAL INSPECTION:\")\n",
        "print(\"  ‚Ä¢ Box plots show points beyond whiskers = potential outliers\")\n",
        "print(\"  ‚Ä¢ Histograms show extreme values on the tails\")\n",
        "print(\"  ‚Ä¢ Notice how outliers affect the mean vs median\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "296f64d2",
      "metadata": {},
      "source": [
        "## Method 1: Interquartile Range (IQR) Method\n",
        "\n",
        "The **IQR method** is one of the most popular statistical techniques for outlier detection.\n",
        "\n",
        "### How IQR Works:\n",
        "\n",
        "1. **Calculate Q1 (25th percentile)** and **Q3 (75th percentile)**\n",
        "2. **Calculate IQR** = Q3 - Q1\n",
        "3. **Define boundaries:**\n",
        "   - Lower Bound = Q1 - 1.5 √ó IQR\n",
        "   - Upper Bound = Q3 + 1.5 √ó IQR\n",
        "4. **Outliers** = values outside these boundaries\n",
        "\n",
        "### Why 1.5 √ó IQR?\n",
        "- Standard convention in statistics\n",
        "- Identifies values in the extreme tails\n",
        "- Can be adjusted (1.5 for moderate, 3.0 for extreme outliers)\n",
        "\n",
        "### Advantages:\n",
        "‚úÖ Simple and intuitive\n",
        "‚úÖ Robust to extreme values\n",
        "‚úÖ Works well with skewed distributions\n",
        "‚úÖ Visualized in box plots\n",
        "\n",
        "### Disadvantages:\n",
        "‚ùå Only works for univariate data\n",
        "‚ùå May not detect multivariate outliers\n",
        "‚ùå Assumes specific distribution shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d4b220",
      "metadata": {},
      "outputs": [],
      "source": [
        "# IQR Method for Outlier Detection\n",
        "def detect_outliers_iqr(data, column, multiplier=1.5):\n",
        "    \"\"\"Detect outliers using IQR method\"\"\"\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    lower_bound = Q1 - multiplier * IQR\n",
        "    upper_bound = Q3 + multiplier * IQR\n",
        "    \n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "    \n",
        "    return outliers, lower_bound, upper_bound, Q1, Q3, IQR\n",
        "\n",
        "print(\"IQR METHOD FOR OUTLIER DETECTION\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Apply IQR method to each column\n",
        "results_iqr = {}\n",
        "for column in ['Values', 'Age', 'Salary']:\n",
        "    outliers, lower, upper, q1, q3, iqr = detect_outliers_iqr(df, column)\n",
        "    results_iqr[column] = {\n",
        "        'outliers': outliers,\n",
        "        'count': len(outliers),\n",
        "        'lower_bound': lower,\n",
        "        'upper_bound': upper,\n",
        "        'Q1': q1,\n",
        "        'Q3': q3,\n",
        "        'IQR': iqr\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"  Q1 (25th percentile): {q1:.2f}\")\n",
        "    print(f\"  Q3 (75th percentile): {q3:.2f}\")\n",
        "    print(f\"  IQR: {iqr:.2f}\")\n",
        "    print(f\"  Lower Bound: {lower:.2f}\")\n",
        "    print(f\"  Upper Bound: {upper:.2f}\")\n",
        "    print(f\"  Outliers Detected: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  Outlier values: {sorted(outliers[column].values)[:10]}\")  # Show first 10\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('IQR Method: Outlier Detection', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, column in enumerate(['Values', 'Age', 'Salary']):\n",
        "    # Scatter plot with outliers highlighted\n",
        "    normal_data = df[~df.index.isin(results_iqr[column]['outliers'].index)]\n",
        "    outlier_data = results_iqr[column]['outliers']\n",
        "    \n",
        "    axes[idx].scatter(normal_data.index, normal_data[column], \n",
        "                     c='blue', label='Normal', alpha=0.6, s=30)\n",
        "    axes[idx].scatter(outlier_data.index, outlier_data[column], \n",
        "                     c='red', label='Outliers', alpha=0.9, s=80, marker='x', linewidths=3)\n",
        "    \n",
        "    # Add boundary lines\n",
        "    axes[idx].axhline(y=results_iqr[column]['lower_bound'], color='orange', \n",
        "                     linestyle='--', linewidth=2, label='Lower Bound')\n",
        "    axes[idx].axhline(y=results_iqr[column]['upper_bound'], color='orange', \n",
        "                     linestyle='--', linewidth=2, label='Upper Bound')\n",
        "    axes[idx].axhline(y=results_iqr[column]['Q1'], color='green', \n",
        "                     linestyle=':', linewidth=1, alpha=0.5, label='Q1')\n",
        "    axes[idx].axhline(y=results_iqr[column]['Q3'], color='green', \n",
        "                     linestyle=':', linewidth=1, alpha=0.5, label='Q3')\n",
        "    \n",
        "    axes[idx].set_xlabel('Index', fontweight='bold')\n",
        "    axes[idx].set_ylabel(column, fontweight='bold')\n",
        "    axes[idx].set_title(f'{column}: {len(outlier_data)} Outliers', fontweight='bold')\n",
        "    axes[idx].legend(loc='best', fontsize=8)\n",
        "    axes[idx].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Remove outliers\n",
        "df_no_outliers_iqr = df.copy()\n",
        "for column in ['Values', 'Age', 'Salary']:\n",
        "    outlier_indices = results_iqr[column]['outliers'].index\n",
        "    df_no_outliers_iqr = df_no_outliers_iqr.drop(outlier_indices)\n",
        "\n",
        "df_no_outliers_iqr = df_no_outliers_iqr.drop_duplicates()  # Remove any duplicates\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"DATASET AFTER REMOVING OUTLIERS (IQR Method):\")\n",
        "print(f\"  Original size: {len(df)} rows\")\n",
        "print(f\"  After removal: {len(df_no_outliers_iqr)} rows\")\n",
        "print(f\"  Removed: {len(df) - len(df_no_outliers_iqr)} rows ({(len(df) - len(df_no_outliers_iqr))/len(df)*100:.1f}%)\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "703bfcdc",
      "metadata": {},
      "source": [
        "## Method 2: Z-Score Method\n",
        "\n",
        "The **Z-Score method** measures how many standard deviations a data point is from the mean.\n",
        "\n",
        "### How Z-Score Works:\n",
        "\n",
        "**Formula:** Z = (X - Œº) / œÉ\n",
        "- X = data point\n",
        "- Œº = mean\n",
        "- œÉ = standard deviation\n",
        "\n",
        "**Threshold:** Typically |Z| > 3 indicates an outlier\n",
        "- |Z| > 2: Moderate outlier (95% confidence)\n",
        "- |Z| > 3: Extreme outlier (99.7% confidence)\n",
        "\n",
        "### When to Use:\n",
        "- Data is normally distributed (or approximately)\n",
        "- Want to use statistical significance\n",
        "- Need standardized measure across features\n",
        "\n",
        "### Advantages:\n",
        "‚úÖ Based on statistical theory\n",
        "‚úÖ Easy to interpret (in terms of standard deviations)\n",
        "‚úÖ Works well with normal distributions\n",
        "‚úÖ Standardized across different scales\n",
        "\n",
        "### Disadvantages:\n",
        "‚ùå Assumes normal distribution\n",
        "‚ùå Sensitive to extreme outliers (affects mean and std)\n",
        "‚ùå Not robust for skewed data\n",
        "‚ùå Only for univariate analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22cf0709",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Z-Score Method\n",
        "def detect_outliers_zscore(data, column, threshold=3):\n",
        "    \"\"\"Detect outliers using Z-score method\"\"\"\n",
        "    mean = data[column].mean()\n",
        "    std = data[column].std()\n",
        "    \n",
        "    z_scores = np.abs((data[column] - mean) / std)\n",
        "    outliers = data[z_scores > threshold]\n",
        "    \n",
        "    return outliers, z_scores, mean, std\n",
        "\n",
        "print(\"Z-SCORE METHOD FOR OUTLIER DETECTION\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "results_zscore = {}\n",
        "for column in ['Values', 'Age', 'Salary']:\n",
        "    outliers, z_scores, mean, std = detect_outliers_zscore(df, column, threshold=3)\n",
        "    results_zscore[column] = {\n",
        "        'outliers': outliers,\n",
        "        'z_scores': z_scores,\n",
        "        'count': len(outliers),\n",
        "        'mean': mean,\n",
        "        'std': std\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{column}:\")\n",
        "    print(f\"  Mean: {mean:.2f}\")\n",
        "    print(f\"  Std Dev: {std:.2f}\")\n",
        "    print(f\"  Threshold: 3 standard deviations\")\n",
        "    print(f\"  Outliers Detected: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  Outlier values: {sorted(outliers[column].values)[:10]}\")\n",
        "        print(f\"  Max Z-score: {z_scores.max():.2f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Z-Score Method: Outlier Detection', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, column in enumerate(['Values', 'Age', 'Salary']):\n",
        "    # Z-score distribution\n",
        "    z_scores = results_zscore[column]['z_scores']\n",
        "    axes[0, idx].hist(z_scores, bins=30, color='lightblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, idx].axvline(x=3, color='red', linestyle='--', linewidth=2, label='Threshold (3œÉ)')\n",
        "    axes[0, idx].axvline(x=-3, color='red', linestyle='--', linewidth=2)\n",
        "    axes[0, idx].set_xlabel('Z-Score', fontweight='bold')\n",
        "    axes[0, idx].set_ylabel('Frequency', fontweight='bold')\n",
        "    axes[0, idx].set_title(f'{column}: Z-Score Distribution', fontweight='bold')\n",
        "    axes[0, idx].legend()\n",
        "    axes[0, idx].grid(alpha=0.3)\n",
        "    \n",
        "    # Scatter plot with outliers\n",
        "    normal_mask = z_scores <= 3\n",
        "    axes[1, idx].scatter(df[normal_mask].index, df[normal_mask][column], \n",
        "                        c='blue', label='Normal', alpha=0.6, s=30)\n",
        "    axes[1, idx].scatter(results_zscore[column]['outliers'].index, \n",
        "                        results_zscore[column]['outliers'][column], \n",
        "                        c='red', label='Outliers', alpha=0.9, s=80, marker='x', linewidths=3)\n",
        "    axes[1, idx].axhline(y=results_zscore[column]['mean'], color='green', \n",
        "                        linestyle='--', linewidth=2, label='Mean')\n",
        "    axes[1, idx].set_xlabel('Index', fontweight='bold')\n",
        "    axes[1, idx].set_ylabel(column, fontweight='bold')\n",
        "    axes[1, idx].set_title(f'{column}: {len(results_zscore[column][\"outliers\"])} Outliers', fontweight='bold')\n",
        "    axes[1, idx].legend()\n",
        "    axes[1, idx].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"üí° Z-SCORE INTERPRETATION:\")\n",
        "print(\"  ‚Ä¢ |Z| < 2: Within normal range (95% of data)\")\n",
        "print(\"  ‚Ä¢ 2 < |Z| < 3: Moderate outlier\")\n",
        "print(\"  ‚Ä¢ |Z| > 3: Extreme outlier (only 0.3% of normal data)\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbea030f",
      "metadata": {},
      "source": [
        "## Method 3: Isolation Forest\n",
        "\n",
        "**Isolation Forest** is a machine learning algorithm specifically designed for anomaly/outlier detection.\n",
        "\n",
        "### How Isolation Forest Works:\n",
        "\n",
        "1. **Randomly select a feature** and split value\n",
        "2. **Recursively partition data** (create decision trees)\n",
        "3. **Outliers are isolated faster** (fewer splits needed)\n",
        "4. **Anomaly score** based on path length to isolate the point\n",
        "\n",
        "**Key Idea:** Outliers are \"few and different\", so they're easier to isolate than normal points.\n",
        "\n",
        "### Why It's Effective:\n",
        "- Outliers require fewer splits to isolate\n",
        "- Normal points are clustered together (many splits needed)\n",
        "- Uses ensemble of isolation trees\n",
        "\n",
        "### When to Use:\n",
        "- High-dimensional data\n",
        "- Multivariate outlier detection\n",
        "- No assumptions about data distribution\n",
        "- Large datasets\n",
        "\n",
        "### Advantages:\n",
        "‚úÖ Handles multivariate outliers\n",
        "‚úÖ No assumptions about distribution\n",
        "‚úÖ Efficient with large datasets\n",
        "‚úÖ Can handle high dimensions\n",
        "‚úÖ Based on machine learning\n",
        "\n",
        "### Disadvantages:\n",
        "‚ùå Less interpretable (black box)\n",
        "‚ùå Requires parameter tuning\n",
        "‚ùå May not work well with small datasets\n",
        "‚ùå Computational overhead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9547945a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Isolation Forest Method\n",
        "print(\"ISOLATION FOREST METHOD\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Apply Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)  # Expect 5% outliers\n",
        "predictions = iso_forest.fit_predict(df[['Values', 'Age', 'Salary']])\n",
        "\n",
        "# -1 for outliers, 1 for inliers\n",
        "df['ISO_Outlier'] = predictions\n",
        "outliers_iso = df[df['ISO_Outlier'] == -1]\n",
        "inliers_iso = df[df['ISO_Outlier'] == 1]\n",
        "\n",
        "print(f\"\\nContamination Parameter: 0.05 (expect ~5% outliers)\")\n",
        "print(f\"Outliers Detected: {len(outliers_iso)} ({len(outliers_iso)/len(df)*100:.1f}%)\")\n",
        "print(f\"Inliers: {len(inliers_iso)} ({len(inliers_iso)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"Sample Outliers Detected:\")\n",
        "print(outliers_iso[['Values', 'Age', 'Salary']].head(10))\n",
        "\n",
        "# Anomaly scores\n",
        "anomaly_scores = iso_forest.score_samples(df[['Values', 'Age', 'Salary']])\n",
        "df['Anomaly_Score'] = anomaly_scores\n",
        "\n",
        "# Visualization\n",
        "fig = plt.figure(figsize=(18, 10))\n",
        "gs = fig.add_gridspec(2, 3, hspace=0.3)\n",
        "\n",
        "# 2D scatter plots for each pair of features\n",
        "feature_pairs = [('Values', 'Age'), ('Values', 'Salary'), ('Age', 'Salary')]\n",
        "\n",
        "for idx, (feat1, feat2) in enumerate(feature_pairs):\n",
        "    ax = fig.add_subplot(gs[0, idx])\n",
        "    \n",
        "    # Plot inliers and outliers\n",
        "    ax.scatter(inliers_iso[feat1], inliers_iso[feat2], \n",
        "              c='blue', label='Inliers', alpha=0.6, s=30)\n",
        "    ax.scatter(outliers_iso[feat1], outliers_iso[feat2], \n",
        "              c='red', label='Outliers', alpha=0.9, s=100, marker='x', linewidths=3)\n",
        "    \n",
        "    ax.set_xlabel(feat1, fontweight='bold')\n",
        "    ax.set_ylabel(feat2, fontweight='bold')\n",
        "    ax.set_title(f'Isolation Forest: {feat1} vs {feat2}', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "# Anomaly score distribution\n",
        "ax = fig.add_subplot(gs[1, :])\n",
        "ax.hist(inliers_iso['Anomaly_Score'], bins=30, alpha=0.7, label='Inliers', \n",
        "        color='blue', edgecolor='black')\n",
        "ax.hist(outliers_iso['Anomaly_Score'], bins=30, alpha=0.7, label='Outliers', \n",
        "        color='red', edgecolor='black')\n",
        "ax.set_xlabel('Anomaly Score', fontweight='bold', fontsize=12)\n",
        "ax.set_ylabel('Frequency', fontweight='bold', fontsize=12)\n",
        "ax.set_title('Anomaly Score Distribution', fontweight='bold', fontsize=14)\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Isolation Forest: Multivariate Outlier Detection', \n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare with other methods\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"METHOD COMPARISON:\")\n",
        "print(\"=\" * 100)\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Method': ['IQR', 'Z-Score', 'Isolation Forest'],\n",
        "    'Outliers_Detected': [\n",
        "        sum([results_iqr[col]['count'] for col in ['Values', 'Age', 'Salary']]),\n",
        "        sum([results_zscore[col]['count'] for col in ['Values', 'Age', 'Salary']]),\n",
        "        len(outliers_iso)\n",
        "    ],\n",
        "    'Type': ['Univariate', 'Univariate', 'Multivariate']\n",
        "})\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"üí° KEY INSIGHTS:\")\n",
        "print(\"  ‚Ä¢ IQR & Z-Score: Detect outliers in each feature independently\")\n",
        "print(\"  ‚Ä¢ Isolation Forest: Detects multivariate outliers (unusual combinations)\")\n",
        "print(\"  ‚Ä¢ A point can be normal in each feature but outlier in combination\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "136ee77a",
      "metadata": {},
      "source": [
        "## Handling Strategies: What to Do with Outliers\n",
        "\n",
        "Once outliers are detected, you have several options for handling them.\n",
        "\n",
        "### Strategy 1: Remove Outliers\n",
        "**When:** Confirmed errors, measurement mistakes\n",
        "**Code:** `df_clean = df[~outlier_mask]`\n",
        "\n",
        "### Strategy 2: Cap/Winsorize\n",
        "**When:** Want to retain data but limit extreme values\n",
        "**Code:** Set outliers to boundary values (e.g., 5th and 95th percentiles)\n",
        "\n",
        "### Strategy 3: Transform Data\n",
        "**When:** Reduce impact of outliers\n",
        "**Methods:** Log transformation, square root, Box-Cox\n",
        "\n",
        "### Strategy 4: Impute Outliers\n",
        "**When:** Outliers are errors but removing loses info\n",
        "**Code:** Replace with median, mean, or predicted values\n",
        "\n",
        "### Strategy 5: Keep Them\n",
        "**When:** Outliers are legitimate rare events\n",
        "**Use:** Robust algorithms (tree-based models) or separate analysis\n",
        "\n",
        "Let's implement these strategies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cbf6ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate different handling strategies\n",
        "print(\"OUTLIER HANDLING STRATEGIES\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Use 'Values' column for demonstration\n",
        "column = 'Values'\n",
        "data_original = df[column].copy()\n",
        "\n",
        "# Strategy 1: Remove outliers (already shown)\n",
        "outliers_iqr, lower, upper, _, _, _ = detect_outliers_iqr(df, column)\n",
        "data_removed = df[~df.index.isin(outliers_iqr.index)][column]\n",
        "\n",
        "# Strategy 2: Cap/Winsorize (clip to boundaries)\n",
        "data_capped = data_original.copy()\n",
        "data_capped = data_capped.clip(lower=lower, upper=upper)\n",
        "\n",
        "# Strategy 3: Log transformation\n",
        "data_log = np.log1p(data_original - data_original.min() + 1)  # Shift to positive\n",
        "\n",
        "# Strategy 4: Impute with median\n",
        "data_imputed = data_original.copy()\n",
        "outlier_mask = (data_original < lower) | (data_original > upper)\n",
        "data_imputed[outlier_mask] = data_original.median()\n",
        "\n",
        "# Strategy 5: Keep as is\n",
        "data_keep = data_original.copy()\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Outlier Handling Strategies Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "strategies = [\n",
        "    ('Original Data', data_original),\n",
        "    ('Removed', data_removed),\n",
        "    ('Capped/Winsorized', data_capped),\n",
        "    ('Log Transformed', data_log),\n",
        "    ('Imputed (Median)', data_imputed),\n",
        "    ('Keep Outliers', data_keep)\n",
        "]\n",
        "\n",
        "for idx, (title, data) in enumerate(strategies):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    \n",
        "    axes[row, col].hist(data, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    axes[row, col].axvline(data.mean(), color='red', linestyle='--', \n",
        "                           linewidth=2, label=f'Mean: {data.mean():.1f}')\n",
        "    axes[row, col].axvline(data.median(), color='green', linestyle='--', \n",
        "                           linewidth=2, label=f'Median: {data.median():.1f}')\n",
        "    axes[row, col].set_xlabel(column, fontweight='bold')\n",
        "    axes[row, col].set_ylabel('Frequency', fontweight='bold')\n",
        "    axes[row, col].set_title(f'{title} (n={len(data)})', fontweight='bold')\n",
        "    axes[row, col].legend(fontsize=8)\n",
        "    axes[row, col].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics comparison\n",
        "print(\"\\nSTATISTICS COMPARISON:\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"{'Strategy':<20} {'Count':<8} {'Mean':<10} {'Median':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for title, data in strategies:\n",
        "    print(f\"{title:<20} {len(data):<8} {data.mean():<10.2f} {data.median():<10.2f} \"\n",
        "          f\"{data.std():<10.2f} {data.min():<10.2f} {data.max():<10.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"STRATEGY RECOMMENDATIONS:\")\n",
        "print(\"-\" * 100)\n",
        "print(\"‚úì REMOVE: Best when outliers are confirmed errors\")\n",
        "print(\"‚úì CAP: Retains all data, limits extreme values\")\n",
        "print(\"‚úì TRANSFORM: Reduces skewness, compresses scale\")\n",
        "print(\"‚úì IMPUTE: Replaces outliers but keeps sample size\")\n",
        "print(\"‚úì KEEP: Use with robust models or when outliers are valid\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee09e2e",
      "metadata": {},
      "source": [
        "## Summary: Outlier Detection and Handling Best Practices\n",
        "\n",
        "### Quick Decision Guide\n",
        "\n",
        "| Question | Answer ‚Üí Method |\n",
        "|----------|----------------|\n",
        "| Is data normally distributed? | Yes ‚Üí Z-Score, No ‚Üí IQR |\n",
        "| Need multivariate detection? | Yes ‚Üí Isolation Forest |\n",
        "| Small dataset? | IQR (more robust) |\n",
        "| High dimensions? | Isolation Forest |\n",
        "| Need interpretability? | IQR or Z-Score |\n",
        "\n",
        "### Method Comparison Summary\n",
        "\n",
        "| Method | Best For | Pros | Cons |\n",
        "|--------|----------|------|------|\n",
        "| **IQR** | General purpose, skewed data | Simple, robust, visual | Univariate only |\n",
        "| **Z-Score** | Normal distribution | Statistical, standardized | Assumes normality |\n",
        "| **Isolation Forest** | High-dim, multivariate | No assumptions, ML-based | Less interpretable |\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "‚úÖ **DO:**\n",
        "- Visualize data first (box plots, histograms)\n",
        "- Understand domain context before removing\n",
        "- Document outlier handling decisions\n",
        "- Try multiple detection methods\n",
        "- Consider business impact\n",
        "- Use appropriate method for data distribution\n",
        "- Keep original data backup\n",
        "\n",
        "‚ùå **DON'T:**\n",
        "- Remove outliers blindly\n",
        "- Use Z-score on non-normal data\n",
        "- Forget to check for multivariate outliers\n",
        "- Remove outliers before understanding them\n",
        "- Use same threshold for all features\n",
        "- Ignore domain knowledge\n",
        "\n",
        "### Handling Strategy Selection\n",
        "\n",
        "```\n",
        "Is outlier a DATA ERROR? ‚Üí REMOVE\n",
        "Is outlier LEGITIMATE but extreme? ‚Üí CAP or TRANSFORM\n",
        "Is outlier RARE but VALID event? ‚Üí KEEP (use robust model)\n",
        "Is outlier pattern IMPORTANT? ‚Üí SEPARATE ANALYSIS\n",
        "Unsure? ‚Üí IMPUTE or FLAG for review\n",
        "```\n",
        "\n",
        "### Real-World Tips\n",
        "\n",
        "1. **Always investigate** outliers before removing\n",
        "2. **Domain expertise** is crucial - what's an outlier in one context may be normal in another\n",
        "3. **Multiple methods** - use 2-3 methods and compare results\n",
        "4. **Document everything** - record which outliers removed and why\n",
        "5. **Consider the goal** - fraud detection needs outliers, but regression modeling may not\n",
        "6. **Robust algorithms** - Tree-based models handle outliers naturally\n",
        "7. **Feature-specific thresholds** - different features may need different sensitivity\n",
        "\n",
        "### Code Template\n",
        "\n",
        "```python\n",
        "# 1. Detect outliers\n",
        "def detect_outliers_comprehensive(df, column):\n",
        "    # IQR method\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    iqr_outliers = df[(df[column] < Q1 - 1.5*IQR) | (df[column] > Q3 + 1.5*IQR)]\n",
        "    \n",
        "    # Z-score method\n",
        "    z_scores = np.abs(stats.zscore(df[column]))\n",
        "    z_outliers = df[z_scores > 3]\n",
        "    \n",
        "    return iqr_outliers, z_outliers\n",
        "\n",
        "# 2. Handle based on strategy\n",
        "def handle_outliers(df, column, strategy='cap'):\n",
        "    if strategy == 'remove':\n",
        "        # Remove outliers\n",
        "        outliers, _, _ = detect_outliers_iqr(df, column)\n",
        "        return df[~df.index.isin(outliers.index)]\n",
        "    \n",
        "    elif strategy == 'cap':\n",
        "        # Cap to boundaries\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        df[column] = df[column].clip(lower=lower, upper=upper)\n",
        "        return df\n",
        "    \n",
        "    elif strategy == 'impute':\n",
        "        # Replace with median\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        mask = (df[column] < Q1 - 1.5*IQR) | (df[column] > Q3 + 1.5*IQR)\n",
        "        df.loc[mask, column] = df[column].median()\n",
        "        return df\n",
        "```\n",
        "\n",
        "### Final Recommendations\n",
        "\n",
        "- **Start with visualization** - understand your data\n",
        "- **Use IQR as default** - works well in most cases\n",
        "- **Try Isolation Forest** for complex, high-dimensional data\n",
        "- **Consider the context** - medical data vs sales data have different needs\n",
        "- **Validate results** - check model performance with/without outliers\n",
        "- **Be conservative** - when in doubt, keep the data\n",
        "\n",
        "---\n",
        "\n",
        "**Remember:** Outliers are not always bad! They can be the most interesting and valuable part of your data, especially in fraud detection, quality control, or discovering new patterns."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
