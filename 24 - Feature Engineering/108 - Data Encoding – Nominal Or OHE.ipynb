{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15fb40f9",
      "metadata": {},
      "source": [
        "# Data Encoding: Nominal and One-Hot Encoding (OHE)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Machine learning algorithms work with numbers, not text. **Categorical encoding** converts categorical (text) variables into numerical format that algorithms can process.\n",
        "\n",
        "### Why Do We Need Encoding?\n",
        "\n",
        "Most ML algorithms require numerical input:\n",
        "- Linear Regression, Logistic Regression\n",
        "- Neural Networks\n",
        "- Support Vector Machines (SVM)\n",
        "- K-Nearest Neighbors (KNN)\n",
        "\n",
        "**Example Problem:**\n",
        "```\n",
        "Colors: ['Red', 'Blue', 'Green']\n",
        "ML Algorithm: ‚ùå Cannot process strings\n",
        "Solution: ‚úÖ Encode as numbers\n",
        "```\n",
        "\n",
        "### Types of Categorical Variables\n",
        "\n",
        "**1. Nominal (No Order)**\n",
        "- Categories have no inherent order\n",
        "- Examples: Color (Red, Blue, Green), Country (USA, UK, India), Gender (Male, Female)\n",
        "- **Solution:** One-Hot Encoding\n",
        "\n",
        "**2. Ordinal (Has Order)**\n",
        "- Categories have meaningful order\n",
        "- Examples: Education (High School < Bachelor < Master < PhD), Rating (Bad < Good < Excellent)\n",
        "- **Solution:** Label Encoding or Ordinal Encoding\n",
        "\n",
        "### What is One-Hot Encoding?\n",
        "\n",
        "**One-Hot Encoding (OHE)** creates binary columns for each category, with 1 indicating presence and 0 indicating absence.\n",
        "\n",
        "**Example:**\n",
        "```\n",
        "Original: Color = ['Red', 'Blue', 'Green', 'Red']\n",
        "\n",
        "After OHE:\n",
        "  Color_Red  Color_Blue  Color_Green\n",
        "  1          0           0\n",
        "  0          1           0\n",
        "  0          0           1\n",
        "  1          0           0\n",
        "```\n",
        "\n",
        "### How One-Hot Encoding Works\n",
        "\n",
        "1. **Identify unique categories** in the column\n",
        "2. **Create new binary column** for each category\n",
        "3. **Set 1** where that category appears, **0** elsewhere\n",
        "4. **Drop original column** (optional)\n",
        "\n",
        "### When to Use One-Hot Encoding\n",
        "\n",
        "‚úÖ **Use OHE When:**\n",
        "- Categories are **nominal** (no order)\n",
        "- Number of categories is **small to moderate** (<10-15)\n",
        "- Categories are **equally important**\n",
        "- Using algorithms that can't handle ordinal relationships\n",
        "- Want to avoid imposing false ordinal relationships\n",
        "\n",
        "‚ùå **Avoid OHE When:**\n",
        "- **High cardinality** (many unique categories)\n",
        "- Categories have **ordinal relationship**\n",
        "- **Memory constraints** (creates many columns)\n",
        "- Using **tree-based algorithms** (can handle categories)\n",
        "\n",
        "### Advantages of One-Hot Encoding\n",
        "\n",
        "‚úÖ No ordinal relationship imposed\n",
        "‚úÖ Works with all ML algorithms\n",
        "‚úÖ Each category treated equally\n",
        "‚úÖ Easy to interpret\n",
        "‚úÖ Standard practice for nominal data\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "‚ùå **Curse of dimensionality** - creates many columns\n",
        "‚ùå **Sparse matrices** - mostly zeros\n",
        "‚ùå **Memory intensive** with high cardinality\n",
        "‚ùå **Multicollinearity** - columns are correlated\n",
        "‚ùå Can slow down training\n",
        "\n",
        "### The Dummy Variable Trap\n",
        "\n",
        "When using OHE, we can drop one column to avoid **multicollinearity** (perfect correlation between features).\n",
        "\n",
        "**Example:** If Color_Red=0 and Color_Blue=0, then Color_Green must =1\n",
        "**Solution:** Drop one column (e.g., Color_Green)\n",
        "\n",
        "Let's implement One-Hot Encoding with practical examples!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada69966",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries and Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e07977",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create sample dataset with categorical variables\n",
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    'Customer_ID': range(1, 16),\n",
        "    'Age': [25, 30, 35, 28, 42, 38, 45, 29, 33, 40, 27, 31, 36, 44, 26],\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', \n",
        "               'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'New York',\n",
        "             'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'New York', 'Los Angeles',\n",
        "             'Chicago', 'Houston', 'Phoenix'],\n",
        "    'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet', 'Laptop',\n",
        "                'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet'],\n",
        "    'Purchase_Amount': [1200, 800, 500, 1300, 750, 520, 1250, 820, 510, 1280, 780, 530, 1220, 790, 495]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"=\" * 100)\n",
        "print(\"SAMPLE DATASET WITH CATEGORICAL VARIABLES\")\n",
        "print(\"=\" * 100)\n",
        "print(df)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"DATA TYPES:\")\n",
        "print(\"-\" * 100)\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"CATEGORICAL COLUMNS ANALYSIS:\")\n",
        "print(\"-\" * 100)\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    unique_values = df[col].nunique()\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Unique Values: {unique_values}\")\n",
        "    print(f\"  Categories: {df[col].unique().tolist()}\")\n",
        "    print(f\"  Value Counts:\\n{df[col].value_counts()}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Categorical Variables Distribution', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, col in enumerate(['Gender', 'City', 'Product']):\n",
        "    counts = df[col].value_counts()\n",
        "    axes[idx].bar(counts.index, counts.values, color='skyblue', alpha=0.7, edgecolor='black', linewidth=2)\n",
        "    axes[idx].set_xlabel(col, fontweight='bold', fontsize=12)\n",
        "    axes[idx].set_ylabel('Count', fontweight='bold', fontsize=12)\n",
        "    axes[idx].set_title(f'{col} Distribution', fontweight='bold', fontsize=13)\n",
        "    axes[idx].grid(axis='y', alpha=0.3)\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    for i, (category, count) in enumerate(counts.items()):\n",
        "        axes[idx].text(i, count + 0.1, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"‚úÖ Dataset loaded successfully!\")\n",
        "print(\"   Next: Apply One-Hot Encoding to convert categories to numbers\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528cba9f",
      "metadata": {},
      "source": [
        "## Method 1: Pandas get_dummies()\n",
        "\n",
        "The simplest way to perform One-Hot Encoding in Python is using pandas `get_dummies()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd33a17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: pandas get_dummies()\n",
        "print(\"METHOD 1: PANDAS GET_DUMMIES()\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Apply get_dummies to specific columns\n",
        "df_encoded = pd.get_dummies(df, columns=['Gender', 'City', 'Product'], drop_first=False)\n",
        "\n",
        "print(\"\\nOriginal DataFrame Shape:\", df.shape)\n",
        "print(\"Encoded DataFrame Shape:\", df_encoded.shape)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"ENCODED DATASET (first 10 rows):\")\n",
        "print(\"-\" * 100)\n",
        "print(df_encoded.head(10))\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"NEW COLUMNS CREATED:\")\n",
        "print(\"-\" * 100)\n",
        "new_cols = [col for col in df_encoded.columns if col not in df.columns]\n",
        "print(new_cols)\n",
        "\n",
        "# With drop_first=True (avoid dummy variable trap)\n",
        "df_encoded_drop = pd.get_dummies(df, columns=['Gender', 'City', 'Product'], drop_first=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"COMPARISON: drop_first=False vs drop_first=True\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"Without dropping first: {df_encoded.shape[1]} columns\")\n",
        "print(f\"With dropping first:    {df_encoded_drop.shape[1]} columns\")\n",
        "print(f\"Difference:             {df_encoded.shape[1] - df_encoded_drop.shape[1]} columns dropped\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Show encoding for Gender\n",
        "sample_data = df_encoded[['Customer_ID', 'Gender_Male', 'Gender_Female']].head(8)\n",
        "axes[0].axis('off')\n",
        "table = axes[0].table(cellText=sample_data.values,\n",
        "                      colLabels=sample_data.columns,\n",
        "                      cellLoc='center',\n",
        "                      loc='center',\n",
        "                      colWidths=[0.3, 0.35, 0.35])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1, 2.5)\n",
        "axes[0].set_title('One-Hot Encoding: Gender Example', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "# Column count comparison\n",
        "methods = ['Original', 'OHE (keep all)', 'OHE (drop first)']\n",
        "col_counts = [df.shape[1], df_encoded.shape[1], df_encoded_drop.shape[1]]\n",
        "bars = axes[1].bar(methods, col_counts, color=['blue', 'orange', 'green'], \n",
        "                   alpha=0.7, edgecolor='black', linewidth=2)\n",
        "axes[1].set_ylabel('Number of Columns', fontweight='bold', fontsize=12)\n",
        "axes[1].set_title('Column Count Comparison', fontweight='bold', fontsize=14)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{int(height)}', ha='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"üí° KEY POINTS:\")\n",
        "print(\"  ‚Ä¢ drop_first=False: Creates column for EACH category (default)\")\n",
        "print(\"  ‚Ä¢ drop_first=True: Drops one column per feature (avoids multicollinearity)\")\n",
        "print(\"  ‚Ä¢ For Gender: Male=0, Female=0 implies the dropped category\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "093facbf",
      "metadata": {},
      "source": [
        "## Method 2: Scikit-learn OneHotEncoder\n",
        "\n",
        "For machine learning pipelines, use sklearn's `OneHotEncoder` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36aa66b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: Scikit-learn OneHotEncoder\n",
        "print(\"METHOD 2: SCIKIT-LEARN ONEHOTENCODER\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Initialize encoder\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "\n",
        "# Select categorical columns\n",
        "cat_cols = ['Gender', 'City', 'Product']\n",
        "\n",
        "# Fit and transform\n",
        "encoded_array = encoder.fit_transform(df[cat_cols])\n",
        "\n",
        "# Get feature names\n",
        "feature_names = encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "# Create DataFrame\n",
        "df_sklearn_encoded = pd.DataFrame(encoded_array, columns=feature_names)\n",
        "\n",
        "# Combine with original numerical columns\n",
        "df_final = pd.concat([df[['Customer_ID', 'Age', 'Purchase_Amount']], df_sklearn_encoded], axis=1)\n",
        "\n",
        "print(\"\\nEncoded Array Shape:\", encoded_array.shape)\n",
        "print(\"\\nFeature Names Created:\")\n",
        "print(list(feature_names))\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"FINAL DATASET (first 10 rows):\")\n",
        "print(\"-\" * 100)\n",
        "print(df_final.head(10))\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"ENCODER PROPERTIES:\")\n",
        "print(\"-\" * 100)\n",
        "print(f\"Categories per feature: {[len(cat) for cat in encoder.categories_]}\")\n",
        "print(f\"\\nActual categories:\")\n",
        "for i, col in enumerate(cat_cols):\n",
        "    print(f\"  {col}: {list(encoder.categories_[i])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"‚úÖ ADVANTAGES OF SKLEARN ONEHOTENCODER:\")\n",
        "print(\"  ‚Ä¢ Works in sklearn pipelines\")\n",
        "print(\"  ‚Ä¢ Handles unseen categories\")\n",
        "print(\"  ‚Ä¢ Consistent with train/test split\")\n",
        "print(\"  ‚Ä¢ Can inverse_transform\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe0476b6",
      "metadata": {},
      "source": [
        "## Handling High Cardinality\n",
        "\n",
        "When a categorical variable has many unique values (high cardinality), One-Hot Encoding can create too many columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35cb34d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrating High Cardinality Problem\n",
        "print(\"HIGH CARDINALITY CHALLENGE\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Create high cardinality example\n",
        "np.random.seed(42)\n",
        "high_card_data = {\n",
        "    'Customer_ID': range(1, 101),\n",
        "    'Country': np.random.choice(['USA', 'UK', 'Germany', 'France', 'Spain', 'Italy', \n",
        "                                 'Canada', 'Australia', 'Japan', 'China', 'India', 'Brazil',\n",
        "                                 'Mexico', 'Russia', 'South Korea', 'Netherlands', 'Sweden',\n",
        "                                 'Norway', 'Denmark', 'Finland'], 100),\n",
        "    'Product_ID': [f'PROD_{i:04d}' for i in np.random.randint(1, 51, 100)],\n",
        "    'Sales': np.random.randint(100, 1000, 100)\n",
        "}\n",
        "\n",
        "df_high_card = pd.DataFrame(high_card_data)\n",
        "\n",
        "print(\"\\nDataset with High Cardinality Features:\")\n",
        "print(f\"  Rows: {len(df_high_card)}\")\n",
        "print(f\"  Country unique values: {df_high_card['Country'].nunique()}\")\n",
        "print(f\"  Product_ID unique values: {df_high_card['Product_ID'].nunique()}\")\n",
        "\n",
        "# Apply OHE to see the explosion\n",
        "df_ohe_high = pd.get_dummies(df_high_card, columns=['Country', 'Product_ID'])\n",
        "\n",
        "print(\"\\n\" + \"-\" * 100)\n",
        "print(\"IMPACT OF ONE-HOT ENCODING:\")\n",
        "print(\"-\" * 100)\n",
        "print(f\"Original columns: {df_high_card.shape[1]}\")\n",
        "print(f\"After OHE: {df_ohe_high.shape[1]}\")\n",
        "print(f\"Columns added: {df_ohe_high.shape[1] - df_high_card.shape[1]}\")\n",
        "\n",
        "# Strategies for high cardinality\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"STRATEGIES FOR HIGH CARDINALITY:\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Strategy 1: Keep only top N categories\n",
        "top_n = 5\n",
        "print(f\"\\n1. Keep Top {top_n} Categories + 'Other':\")\n",
        "top_countries = df_high_card['Country'].value_counts().head(top_n).index\n",
        "df_reduced = df_high_card.copy()\n",
        "df_reduced['Country_Grouped'] = df_reduced['Country'].apply(\n",
        "    lambda x: x if x in top_countries else 'Other'\n",
        ")\n",
        "print(f\"   Original unique values: {df_high_card['Country'].nunique()}\")\n",
        "print(f\"   After grouping: {df_reduced['Country_Grouped'].nunique()}\")\n",
        "\n",
        "# Strategy 2: Frequency encoding\n",
        "freq_encoding = df_high_card['Country'].value_counts() / len(df_high_card)\n",
        "df_freq = df_high_card.copy()\n",
        "df_freq['Country_Frequency'] = df_freq['Country'].map(freq_encoding)\n",
        "print(f\"\\n2. Frequency Encoding:\")\n",
        "print(f\"   Sample: {dict(list(freq_encoding.head(3).items()))}\")\n",
        "\n",
        "# Strategy 3: Target encoding (if we have a target variable)\n",
        "target_mean = df_high_card.groupby('Country')['Sales'].mean()\n",
        "df_target = df_high_card.copy()\n",
        "df_target['Country_Target_Encoded'] = df_target['Country'].map(target_mean)\n",
        "print(f\"\\n3. Target Encoding (Mean Sales by Country):\")\n",
        "print(f\"   Sample: {dict(list(target_mean.head(3).items()))}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle('High Cardinality Handling Strategies', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Original distribution\n",
        "country_counts = df_high_card['Country'].value_counts().head(10)\n",
        "axes[0, 0].barh(country_counts.index, country_counts.values, color='skyblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Count', fontweight='bold')\n",
        "axes[0, 0].set_title('Original: Top 10 Countries', fontweight='bold')\n",
        "axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# After grouping\n",
        "grouped_counts = df_reduced['Country_Grouped'].value_counts()\n",
        "axes[0, 1].bar(grouped_counts.index, grouped_counts.values, color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_xlabel('Country Group', fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Count', fontweight='bold')\n",
        "axes[0, 1].set_title(f'After Grouping (Top {top_n} + Other)', fontweight='bold')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Column explosion comparison\n",
        "methods = ['Original', 'OHE\\n(all categories)', 'OHE\\n(top 5 + Other)']\n",
        "columns = [df_high_card.shape[1], df_ohe_high.shape[1], \n",
        "           pd.get_dummies(df_reduced, columns=['Country_Grouped']).shape[1]]\n",
        "colors_comp = ['blue', 'red', 'green']\n",
        "bars = axes[1, 0].bar(methods, columns, color=colors_comp, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "axes[1, 0].set_ylabel('Number of Columns', fontweight='bold')\n",
        "axes[1, 0].set_title('Column Count Comparison', fontweight='bold')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                   f'{int(height)}', ha='center', fontweight='bold')\n",
        "\n",
        "# Encoding methods comparison\n",
        "axes[1, 1].axis('off')\n",
        "summary_text = f\"\"\"\n",
        "ENCODING METHOD COMPARISON\n",
        "\n",
        "Original Features:\n",
        "‚Ä¢ Country: {df_high_card['Country'].nunique()} unique values\n",
        "‚Ä¢ Product_ID: {df_high_card['Product_ID'].nunique()} unique values\n",
        "\n",
        "One-Hot Encoding Results:\n",
        "‚Ä¢ Columns created: {df_ohe_high.shape[1] - df_high_card.shape[1]}\n",
        "‚Ä¢ Total columns: {df_ohe_high.shape[1]}\n",
        "\n",
        "Alternative Strategies:\n",
        "1. Top-N + Other: {pd.get_dummies(df_reduced, columns=['Country_Grouped']).shape[1]} columns\n",
        "2. Frequency Encoding: +1 column per feature\n",
        "3. Target Encoding: +1 column per feature\n",
        "\n",
        "Recommendation: Use frequency or target encoding\n",
        "for high cardinality (>10-15 categories)\n",
        "\"\"\"\n",
        "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
        "               verticalalignment='center',\n",
        "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"üí° HIGH CARDINALITY BEST PRACTICES:\")\n",
        "print(\"  ‚Ä¢ < 10 categories: Use One-Hot Encoding\")\n",
        "print(\"  ‚Ä¢ 10-50 categories: Group rare categories or use target encoding\")\n",
        "print(\"  ‚Ä¢ > 50 categories: Avoid OHE, use frequency/target encoding\")\n",
        "print(\"  ‚Ä¢ Consider domain knowledge for grouping\")\n",
        "print(\"=\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85ad590",
      "metadata": {},
      "source": [
        "## Summary: One-Hot Encoding Best Practices\n",
        "\n",
        "### Quick Decision Guide\n",
        "\n",
        "| Unique Categories | Recommendation |\n",
        "|-------------------|----------------|\n",
        "| 2-10 | ‚úÖ Use One-Hot Encoding |\n",
        "| 10-20 | ‚ö†Ô∏è Use OHE with caution or group rare categories |\n",
        "| 20-50 | ‚ùå Avoid OHE, use target/frequency encoding |\n",
        "| 50+ | ‚ùå Never use OHE, use embeddings or other methods |\n",
        "\n",
        "### pandas get_dummies() vs sklearn OneHotEncoder\n",
        "\n",
        "| Feature | pandas get_dummies() | sklearn OneHotEncoder |\n",
        "|---------|---------------------|----------------------|\n",
        "| **Simplicity** | ‚úÖ Very simple | Slightly more complex |\n",
        "| **Pipeline Integration** | ‚ùå No | ‚úÖ Yes |\n",
        "| **Handle Unknown Categories** | ‚ùå No | ‚úÖ Yes (with handle_unknown='ignore') |\n",
        "| **Inverse Transform** | ‚ùå No | ‚úÖ Yes |\n",
        "| **Sparse Matrix** | ‚ùå No (dense only) | ‚úÖ Yes (memory efficient) |\n",
        "| **Best For** | Quick analysis, EDA | Production ML pipelines |\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "‚úÖ **DO:**\n",
        "- Use OHE for nominal (non-ordinal) categorical variables\n",
        "- Drop first category to avoid multicollinearity (drop_first=True)\n",
        "- Check cardinality before encoding\n",
        "- Use sklearn OneHotEncoder for production pipelines\n",
        "- Encode after train-test split to avoid data leakage\n",
        "- Document which categories were encoded\n",
        "- Handle missing values before encoding\n",
        "\n",
        "‚ùå **DON'T:**\n",
        "- Use OHE for ordinal variables (use ordinal encoding instead)\n",
        "- Use OHE with high cardinality (>15-20 categories)\n",
        "- Encode before splitting data (causes data leakage)\n",
        "- Forget to handle unseen categories in test data\n",
        "- Use OHE when tree-based models can handle categories directly\n",
        "- Create too many sparse columns (memory issues)\n",
        "\n",
        "### Common Pitfalls\n",
        "\n",
        "**1. Data Leakage**\n",
        "```python\n",
        "# ‚ùå WRONG - encoding before split\n",
        "df_encoded = pd.get_dummies(df)\n",
        "X_train, X_test = train_test_split(df_encoded)\n",
        "\n",
        "# ‚úÖ CORRECT - split first, then encode\n",
        "X_train, X_test = train_test_split(df)\n",
        "X_train_encoded = pd.get_dummies(X_train)\n",
        "X_test_encoded = pd.get_dummies(X_test)\n",
        "```\n",
        "\n",
        "**2. Unseen Categories in Test Data**\n",
        "```python\n",
        "# ‚ùå WRONG - may have different columns\n",
        "X_train_ohe = pd.get_dummies(X_train)\n",
        "X_test_ohe = pd.get_dummies(X_test)  # Different categories!\n",
        "\n",
        "# ‚úÖ CORRECT - use sklearn encoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder.fit(X_train)\n",
        "X_train_ohe = encoder.transform(X_train)\n",
        "X_test_ohe = encoder.transform(X_test)\n",
        "```\n",
        "\n",
        "**3. The Dummy Variable Trap**\n",
        "```python\n",
        "# ‚ö†Ô∏è Creates multicollinearity\n",
        "df_ohe = pd.get_dummies(df, drop_first=False)\n",
        "\n",
        "# ‚úÖ Avoids multicollinearity\n",
        "df_ohe = pd.get_dummies(df, drop_first=True)\n",
        "```\n",
        "\n",
        "### When NOT to Use One-Hot Encoding\n",
        "\n",
        "1. **Ordinal Data** - Use Label/Ordinal Encoding instead\n",
        "2. **High Cardinality** - Use target/frequency encoding\n",
        "3. **Tree-based Models** - Can handle categories natively\n",
        "4. **Deep Learning** - Use embeddings for categories\n",
        "5. **Memory Constraints** - Creates sparse matrices\n",
        "\n",
        "### Code Template\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Split data first\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# 2. Initialize encoder\n",
        "encoder = OneHotEncoder(\n",
        "    drop='first',  # Avoid dummy variable trap\n",
        "    sparse_output=False,  # Return dense array\n",
        "    handle_unknown='ignore'  # Handle unseen categories\n",
        ")\n",
        "\n",
        "# 3. Fit on training data only\n",
        "encoder.fit(X_train[categorical_cols])\n",
        "\n",
        "# 4. Transform both sets\n",
        "X_train_encoded = encoder.transform(X_train[categorical_cols])\n",
        "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
        "\n",
        "# 5. Get feature names\n",
        "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
        "```\n",
        "\n",
        "### Final Recommendations\n",
        "\n",
        "- **For EDA/Quick Analysis**: Use `pd.get_dummies()`\n",
        "- **For ML Pipelines**: Use `sklearn.preprocessing.OneHotEncoder`\n",
        "- **For High Cardinality**: Consider target encoding or embeddings\n",
        "- **For Ordinal Data**: Use ordinal encoding (next notebook!)\n",
        "\n",
        "---\n",
        "\n",
        "**You've mastered One-Hot Encoding!** Next, we'll learn about Label and Ordinal Encoding for ordered categorical variables."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
